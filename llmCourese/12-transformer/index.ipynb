{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9f4e11-07a5-4b43-8b3b-7511c6c70009",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 神经网络与Transformer详解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21114b4-6e2c-498a-89e5-412bba28486a",
   "metadata": {},
   "source": [
    "# 1. 一个模型的典型场景"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba79abda-b2c1-4523-9bfa-a90834bea892",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 对用户咨询的法律问题做自动归类：\n",
    "\n",
    "### 婚姻纠纷、劳动纠纷、合同纠纷、债权债务、房产纠纷、交通事故、医疗纠纷、版权纠纷\n",
    "\n",
    "<img src=\"用户对话.png\" alt=\"Image Description\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e5d26b4-7760-41f4-a059-0e853c21ac45",
   "metadata": {},
   "source": [
    "# 2. 模型就是一个数学公式\n",
    "\n",
    "\n",
    "#### 我们一般将这样的问题描述为：给定一组输入数据，经过一系列数学公式计算后，输出n个概率，分别代表该用户对话属于某分类的概率\n",
    "\n",
    "#### 举个非常简单的例子：\n",
    "\n",
    "<img src=\"鳄鱼与蛇1.png\" alt=\"Image Description\" width=\"350\"/><img src=\"鳄鱼与蛇2.png\" alt=\"Image Description\" width=\"650\"/>\n",
    "<img src=\"鳄鱼与蛇3.png\" alt=\"Image Description\" width=\"500\"/><img src=\"鳄鱼与蛇4.png\" alt=\"Image Description\" width=\"500\"/>\n",
    "<img src=\"鳄鱼与蛇5.png\" alt=\"Image Description\" width=\"500\"/><img src=\"鳄鱼与蛇6.png\" alt=\"Image Description\" width=\"500\"/>\n",
    "<img src=\"鳄鱼与蛇7.png\" alt=\"Image Description\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5059a354-bc0b-45f5-b908-2d0473a8a5db",
   "metadata": {},
   "source": [
    "# 3. 万金油公式 - 神经网络\n",
    "\n",
    "## 确定数学公式的过程\n",
    "\n",
    "#### 1、公式：y = ax + b\n",
    "#### 2、参数：a = 50， b = -100\n",
    "\n",
    "#### 真实场景的任务，人类搞不定\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b56f29-5bb3-47ab-9f03-b80928862bf2",
   "metadata": {},
   "source": [
    "## 神经网络的公式结构\n",
    "\n",
    "### MNIST（Mixed National Institute of Standards and Technology database）\n",
    "\n",
    "#### 包含了70,000张手写数字的图像，其中60,000张用于训练，10,000张用于测试，每张图像的内容只包含一个手写数字，从0到9的其中一个数字。\n",
    "#### 任务：给定一张28x28像素的灰度图像，经过一系列数学公式计算后，输出10个概率，分别代表该图像中的内容是0-9某个数字的概率\n",
    "<img src=\"MNIST.png\" width=\"700\"/>\n",
    "\n",
    "<img src=\"MNIST4.png\" width=\"500\"/><img src=\"MNIST2.png\" width=\"525\"/>\n",
    "<br/><br/>\n",
    "\n",
    "<img src=\"MNIST3.png\" width=\"600\"/>\n",
    "\n",
    "<img src=\"MNIST7.png\" width=\"700\"/>\n",
    "<img src=\"MNIST6.png\" width=\"1100\"/>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "<ol>\n",
    "这种在输入向量x和输出向量y之间，增加了一层z向量，\n",
    "并且用上述格式的计算公式去计算z向量和y向量中的每一个数值的结构，\n",
    "就叫做神经网络。\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b09edd-e495-41ed-9893-560aa2c836dd",
   "metadata": {},
   "source": [
    "## 神经网络的参数设计\n",
    "#### 1、我可能会这样设计：设定z向量的长度为784，则x向量与z向量等长\n",
    "\n",
    "<img src=\"MNIST8.png\" width=\"500\"/> <img src=\"MNIST9.png\" width=\"500\"/>\n",
    "<br/><br/>\n",
    "\n",
    "#### 2、会这样简化公式：z[i] = x[i+1] - x[i]（下一个像素值-当前像素值）\n",
    "相当于把公式 z0 = w0 * x0 + w1 * x1 + w2 * x2 + ...... + w782 * x782 + w783 * x783 + w784<br/>\n",
    "的系数 w0设置为-1，w1设置为1，w2及以后的系数全部都设置为0<br/>\n",
    "公式自然变成了 z[0] = x[1] - x[0]<br/>\n",
    "\n",
    "<img src=\"MNIST10.png\" width=\"500\"/> <img src=\"MNIST11.png\" width=\"525\"/>\n",
    "<img src=\"MNIST12.png\" width=\"500\"/><br/>\n",
    "\n",
    "<img src=\"MNIST4.png\" width=\"500\"/> <img src=\"MNIST13.png\" width=\"507\"/>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "#### 3、再加一层z向量\n",
    "\n",
    "<img src=\"MNIST14.png\" width=\"900\"/>\n",
    "<img src=\"MNIST15.png\" width=\"700\"/>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "<ol>\n",
    "<li>在x层和y层之间，加入多层z向量，用以提取更深层特征，这种多层结构，叫做深度神经网络。</li>\n",
    "<li>而通过计算机完成大规模数学计算以找到相对更优的w参数组合的过程，就叫做机器学习，也就是我们所说的模型训练。</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403849e-f265-40e1-843b-cf6da55668ce",
   "metadata": {},
   "source": [
    "# 4. Transformer的模型长什么样\n",
    "### 回到课程最开始的场景\n",
    "<img src=\"用户对话.png\" alt=\"Image Description\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e80c33a-ab2a-4696-a9cf-309de9d5f969",
   "metadata": {},
   "source": [
    "## Tokenization - 文本变成Token\n",
    "\n",
    "### 首先，我们要把这一段文字，变成一组Token，也就是词元化（Tokenization）。\n",
    "\n",
    "⼦词(subword)词元化是词元化的⼀种，这种⽅案把会单词再切得更细⼀些，⽤更基础的单位来表达语⾔。⽐如：\"subword\"这个词，可以拆分成\"sub\"和\"word\"两个⼦词，\"sub\"是⼀个通⽤的前缀可以和其他组合词的\"sub\"前缀合并，这样⼤模型将会学会使⽤\"sub\"前缀。类似的，\"encoded\"可以拆解为\"encod\"+\"ed\"，“encoding”可以拆解为“encod”+\"ing\"，这样两个词的核⼼部分\"encod\"被提取出来了，⽽且还得到时态信息。所以这种子词的处理方式，会让一段内容的Token数量多于单词数量，例如OpenAI的官网上，1000 Tokens大概是750个英文单词上下（500个汉字上下）。\n",
    "\n",
    "<img src=\"transformer01.png\" alt=\"Image Description\" width=\"1000\"/>\n",
    "<img src=\"transformer02.png\" alt=\"Image Description\" width=\"80\"/>\n",
    "<img src=\"transformer03.png\" alt=\"Image Description\" width=\"200\"/>\n",
    "<img src=\"transformer04.png\" alt=\"Image Description\" width=\"1000\"/>\n",
    "<img src=\"transformer05.png\" alt=\"Image Description\" width=\"1000\"/>\n",
    "\n",
    "如果输入内容是：海南麒麟瓜<br/>\n",
    "  海, unicode:28023, utf8:b'\\xe6\\xb5\\xb7'<br/>\n",
    "  南, unicode:21335, utf8:b'\\xe5\\x8d\\x97'<br/>\n",
    "  麒, unicode:40594, utf8:b'\\xe9\\xba\\x92'<br/>\n",
    "  麟, unicode:40607, utf8:b'\\xe9\\xba\\x9f'<br/>\n",
    "  瓜, unicode:29916, utf8:b'\\xe7\\x93\\x9c'<br/><br/>\n",
    "  \n",
    "通过tiktoken处理之后得到的Token序列是：（共11个Token）<br/>\n",
    "  b'\\xe6\\xb5\\xb7'<br/>\n",
    "  b'\\xe5\\x8d\\x97'<br/>\n",
    "  b'\\xe9'<br/>\n",
    "  b'\\xba'<br/>\n",
    "  b'\\x92'<br/>\n",
    "  b'\\xe9'<br/>\n",
    "  b'\\xba'<br/>\n",
    "  b'\\x9f'<br/>\n",
    "  b'\\xe7'<br/>\n",
    "  b'\\x93'<br/>\n",
    "  b'\\x9c'<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349107e0-e917-4a4b-bd63-90afb5e3981f",
   "metadata": {},
   "source": [
    "## Embedding - Token变成向量\n",
    "### one-hot编码\n",
    "\n",
    "<img src=\"transformer06.png\" alt=\"Image Description\" width=\"500\"/>\n",
    "\n",
    "### 比如一句话：“我饿了，你吃了么？”\n",
    "\n",
    "<img src=\"transformer07.png\" alt=\"Image Description\" width=\"500\"/>\n",
    "\n",
    "### one-hot的一些问题\n",
    "\n",
    "#### 1、维度过高，过于稀疏：\n",
    "容纳3000个汉字就需要3000个3000维向量，容纳5000个汉字则需要5000个5000维向量；\n",
    "#### 2、没有体现出“距离”概念：\n",
    "如果两个字之间的意思相近，那两个对应的向量求“距离”的时候，就应该更相近；<br/>\n",
    "<img src=\"transformer08.png\" alt=\"Image Description\" width=\"700\"/>\n",
    "#### 3、没有数学或逻辑关系：\n",
    "最好能满足：国王 - 男人 + 女人 = 女王 <br/><br/>\n",
    "\n",
    "### 需要了解的几个Embedding模型\n",
    "#### 1、Word2Vec：Google在2013年提出的概念，也是一个预训练模型\n",
    "#### 2、OpenAI Embedding Models：就是RAG那节课中，王卓然老师介绍到的OpenAI的API\n",
    "<img src=\"transformer09.png\" alt=\"Image Description\" width=\"700\"/>\n",
    "\n",
    "#### 3、OpenAI Clip Text Encoder：如果一段文本描述的内容，和一张图片包含的内容，是相似或相近的，则生成的向量也是相似度较高的<br/>\n",
    "<img src=\"transformer10.png\" width=\"400\"/><img src=\"transformer11.png\" width=\"400\"/><br/>\n",
    "<img src=\"transformer12.png\" width=\"400\"/><img src=\"transformer13.png\" width=\"400\"/><br/>\n",
    "<img src=\"transformer14.png\" width=\"400\"/><img src=\"transformer15.png\" width=\"400\"/><br/>\n",
    "<img src=\"transformer16.png\" width=\"400\"/><img src=\"transformer17.png\" width=\"400\"/><br/>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "<ol>\n",
    "我们可以通过一个模型把一个Token变成一个Embedding向量、把一个单词变成一个Embedding向量、把一句话变成一个Embedding向量、把一张图变成一个Embedding向量\n",
    "</ol>\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "### 这段对话中有650个字，GPT会把这些汉字转换成大概1300个Token，然后再变成1300个Embedding向量\n",
    "<img src=\"用户对话.png\" width=\"800\"/>\n",
    "<img src=\"transformer19.png\" width=\"800\"/>\n",
    "<img src=\"transformer20.png\" width=\"800\"/>\n",
    "<img src=\"transformer21.png\" width=\"800\"/><br/>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "<ol>\n",
    "把每一个Token都变成一个512的向量之后，这1300个向量只能代表这1300个Token，并不能充分的体现这段文字的语义。\n",
    "</ol>\n",
    "</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba467a-5dab-4f35-8090-58a3d6aaf2df",
   "metadata": {},
   "source": [
    "## Encoder & Decoder\n",
    "\n",
    "<img src=\"Encoder&Decoder01.png\" width=\"800\"/>\n",
    "<img src=\"Encoder&Decoder02.png\" width=\"800\"/>\n",
    "<img src=\"Encoder&Decoder03.png\" width=\"800\"/>\n",
    "<img src=\"Encoder&Decoder04.png\" width=\"800\"/>\n",
    "<img src=\"Encoder&Decoder05.png\" width=\"800\"/>\n",
    "<img src=\"Encoder&Decoder06.png\" width=\"800\"/>\n",
    "\n",
    "### Encoder一般用来做分析，Decoder一般用来做生成，内部核心计算模块以RNN为主\n",
    "<img src=\"Encoder&Decoder07.png\" width=\"800\"/>\n",
    "<img src=\"Encoder&Decoder08.png\" width=\"800\"/>\n",
    "<img src=\"Encoder&Decoder09.png\" width=\"800\"/>\n",
    "<img src=\"Encoder&Decoder10.png\" width=\"1000\"/>\n",
    "<img src=\"Encoder&Decoder11.png\" width=\"1000\"/>\n",
    "\n",
    "### 过去以RNN为核心的Encoder Decoder有以下几个重要的问题\n",
    "#### 1、信息丢失\n",
    "#### 2、无法处理较长句子\n",
    "#### 3、不能并行计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c11c3-24c6-4f37-ba76-3699173526a9",
   "metadata": {},
   "source": [
    "## Transformer Encoder & Decoder\n",
    "\n",
    "### 带有Attention机制的Transformer Encoder\n",
    "<img src=\"T Encoder&Decoder01.png\" width=\"700\"/>\n",
    "<img src=\"T Encoder&Decoder02.png\" width=\"700\"/>\n",
    "<img src=\"T Encoder&Decoder03.png\" width=\"1000\"/>\n",
    "<img src=\"T Encoder&Decoder04.png\" width=\"800\"/>\n",
    "<img src=\"T Encoder&Decoder05.png\" width=\"800\"/>\n",
    "<img src=\"T Encoder&Decoder06.png\" width=\"800\"/>\n",
    "<img src=\"T Encoder&Decoder07.png\" width=\"700\"/>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "<ol>\n",
    "<li>Self-Attention之后的输出，每个向量中，除了包含对应Token的向量数据之外，还加入了上下文中其它所有Token以关联程度为系数的向量数据</li>\n",
    "</ol>\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "<img src=\"T Encoder&Decoder08.png\" width=\"800\"/>\n",
    "<br/><br/>\n",
    "<img src=\"T Encoder&Decoder09.png\" width=\"800\"/>\n",
    "<br/><br/>\n",
    "<img src=\"T Encoder&Decoder10.png\" width=\"800\"/>\n",
    "<br/><br/>\n",
    "<img src=\"T Encoder&Decoder11.png\" width=\"800\"/>\n",
    "<img src=\"T Encoder&Decoder12.png\" width=\"800\"/>\n",
    "<img src=\"T Encoder&Decoder13.png\" width=\"800\"/>\n",
    "\n",
    "<img src=\"T Encoder&Decoder14.png\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f944b72d-6245-419e-88c8-af7be8c2de83",
   "metadata": {},
   "source": [
    "### 带有Attention机制的Transformer Decoder\n",
    "\n",
    "<img src=\"T Encoder&Decoder15.png\" width=\"800\"/>\n",
    "<img src=\"T Encoder&Decoder16.png\" width=\"800\"/>\n",
    "<img src=\"T Encoder&Decoder17.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987b885-4610-43fe-b8ff-80ab1b41d336",
   "metadata": {},
   "source": [
    "### Encoder only & Decoder only\n",
    "\n",
    "<img src=\"T Encoder&Decoder18.png\" width=\"800\"/>\n",
    "<img src=\"T Encoder&Decoder19.png\" width=\"800\"/>\n",
    "<img src=\"T Encoder&Decoder20.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe9264-bccf-4372-a23b-90f9c928f937",
   "metadata": {},
   "source": [
    "# 5. 新模型框架的重要尝试\n",
    "\n",
    "## Transformer的O(n^2)计算复杂度\n",
    "<img src=\"new01.png\" width=\"600\"/>\n",
    "\n",
    "## RWKV的线性注意力机制\n",
    "<img src=\"new02.png\" width=\"800\"/>\n",
    "\n",
    "## Mamba的选择性SSM架构\n",
    "<img src=\"new03.png\" width=\"800\"/>\n",
    "\n",
    "## MoE 混合专家模型\n",
    "<img src=\"new04.png\" width=\"800\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
