{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d0faef-0ef0-4a1b-a7d8-99f59cd72a09",
   "metadata": {},
   "source": [
    "# ğŸ’¡ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ \n",
    "\n",
    "1. LlamaIndex çš„ç‰¹ç‚¹å’ŒåŸºæœ¬ç”¨æ³•\n",
    "2. äº†è§£ LlamaIndex å†…ç½®çš„å·¥å…·\n",
    "3. å¦‚ä½•ç”¨å¥½ SDK ç®€åŒ–åŸºäº LLM çš„åº”ç”¨å¼€å‘\n",
    "\n",
    "å¼€å§‹ä¸Šè¯¾ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207fa56-c6c4-446a-9576-5949d0e6e881",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ğŸ“ è¿™èŠ‚è¯¾æ€ä¹ˆå­¦\n",
    "\n",
    "ä»£ç èƒ½åŠ›è¦æ±‚ï¼š**ä¸­é«˜**ï¼ŒAI/æ•°å­¦åŸºç¡€è¦æ±‚ï¼š**æ— **\n",
    "\n",
    "1. æœ‰ç¼–ç¨‹ä¸è½¯ä»¶å·¥ç¨‹åŸºç¡€çš„åŒå­¦\n",
    "   - å…³æ³¨æ¥å£ä¸å®ç°ç»†èŠ‚ã€é«˜çº§æŠ€å·§ã€å¯æ‰©å±•æ€§\n",
    "2. æ²¡æœ‰ç¼–ç¨‹æˆ–è½¯ä»¶å·¥ç¨‹åŸºç¡€çš„åŒå­¦\n",
    "   - å°½é‡ç†è§£ SDK çš„æ¦‚å¿µå’Œä»·å€¼ï¼Œå°è¯•ä½“ä¼šä½¿ç”¨ SDK å‰åçš„å·®åˆ«ä¸æ„ä¹‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194427bf-5807-49d4-ab25-fa0556f835f3",
   "metadata": {},
   "source": [
    "## 1ã€å¤§è¯­è¨€æ¨¡å‹å¼€å‘æ¡†æ¶çš„ä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60e6e5-8f2a-4cd5-a4b5-824259afc229",
   "metadata": {},
   "source": [
    "_SDKï¼šSoftware Development Kitï¼Œå®ƒæ˜¯ä¸€ç»„è½¯ä»¶å·¥å…·å’Œèµ„æºçš„é›†åˆï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…åˆ›å»ºã€æµ‹è¯•ã€éƒ¨ç½²å’Œç»´æŠ¤åº”ç”¨ç¨‹åºæˆ–è½¯ä»¶ã€‚_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d08668-4981-4b84-ae07-f74cfa191309",
   "metadata": {},
   "source": [
    "æ‰€æœ‰å¼€å‘æ¡†æ¶ï¼ˆSDKï¼‰çš„æ ¸å¿ƒä»·å€¼ï¼Œéƒ½æ˜¯é™ä½å¼€å‘ã€ç»´æŠ¤æˆæœ¬ã€‚\n",
    "\n",
    "å¤§è¯­è¨€æ¨¡å‹å¼€å‘æ¡†æ¶çš„ä»·å€¼ï¼Œæ˜¯è®©å¼€å‘è€…å¯ä»¥æ›´æ–¹ä¾¿åœ°å¼€å‘åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ã€‚ä¸»è¦æä¾›ä¸¤ç±»å¸®åŠ©ï¼š\n",
    "\n",
    "1. ç¬¬ä¸‰æ–¹èƒ½åŠ›æŠ½è±¡ã€‚æ¯”å¦‚ LLMã€å‘é‡æ•°æ®åº“ã€æœç´¢æ¥å£ç­‰\n",
    "2. å¸¸ç”¨å·¥å…·ã€æ–¹æ¡ˆå°è£…\n",
    "3. åº•å±‚å®ç°å°è£…ã€‚æ¯”å¦‚æµå¼æ¥å£ã€è¶…æ—¶é‡è¿ã€å¼‚æ­¥ä¸å¹¶è¡Œç­‰\n",
    "\n",
    "å¥½çš„å¼€å‘æ¡†æ¶ï¼Œéœ€è¦å…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š\n",
    "\n",
    "1. å¯é æ€§ã€é²æ£’æ€§é«˜\n",
    "2. å¯ç»´æŠ¤æ€§é«˜\n",
    "3. å¯æ‰©å±•æ€§é«˜\n",
    "4. å­¦ä¹ æˆæœ¬ä½\n",
    "\n",
    "ä¸¾äº›é€šä¿—çš„ä¾‹å­ï¼š\n",
    "\n",
    "- ä¸å¤–éƒ¨åŠŸèƒ½è§£ä¾èµ–\n",
    "  - æ¯”å¦‚å¯ä»¥éšæ„æ›´æ¢ LLM è€Œä¸ç”¨å¤§é‡é‡æ„ä»£ç \n",
    "  - æ›´æ¢ä¸‰æ–¹å·¥å…·ä¹ŸåŒç†\n",
    "- ç»å¸¸å˜çš„éƒ¨åˆ†è¦åœ¨å¤–éƒ¨ç»´æŠ¤è€Œä¸æ˜¯æ”¾åœ¨ä»£ç é‡Œ\n",
    "  - æ¯”å¦‚ Prompt æ¨¡æ¿\n",
    "- å„ç§ç¯å¢ƒä¸‹éƒ½é€‚ç”¨\n",
    "  - æ¯”å¦‚çº¿ç¨‹å®‰å…¨\n",
    "- æ–¹ä¾¿è°ƒè¯•å’Œæµ‹è¯•\n",
    "  - è‡³å°‘è¦èƒ½æ„Ÿè§‰åˆ°ç”¨äº†æ¯”ä¸ç”¨æ–¹ä¾¿å§\n",
    "  - åˆæ³•çš„è¾“å…¥ä¸ä¼šå¼•å‘æ¡†æ¶å†…éƒ¨çš„æŠ¥é”™\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>åˆ’é‡ç‚¹ï¼š</b>é€‰å¯¹äº†æ¡†æ¶ï¼Œäº‹åŠåŠŸå€ï¼›åä¹‹ï¼Œäº‹å€åŠŸåŠã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b589b-5a4e-451e-baf0-d2a409a9cb4b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>ä»€ä¹ˆæ˜¯ SDK?</b> https://aws.amazon.com/cn/what-is/sdk/\n",
    "<br/>\n",
    "<b>SDK å’Œ API çš„åŒºåˆ«æ˜¯ä»€ä¹ˆ?</b> https://aws.amazon.com/cn/compare/the-difference-between-sdk-and-api/\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30361cf7-ec31-4c45-871e-28ac4f0db1a9",
   "metadata": {},
   "source": [
    "#### ğŸŒ° ä¸¾ä¸ªä¾‹å­ï¼šä½¿ç”¨SDKï¼Œ4 è¡Œä»£ç å®ç°ä¸€ä¸ªç®€æ˜“çš„ RAG ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b734d50-a6eb-43f1-879d-fa00c84d1941",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "è¿è¡Œæœ¬è¯¾ä»£ç å‰ï¼Œè¯·å…ˆé‡å¯ä¸€ä¸‹ kernelï¼Œä»¥é‡ç½®æ‰€æœ‰é…ç½®ã€‚\n",
    "<img src=\"tips.png\" width=400px/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea32ce7-c7a7-4692-a217-45cf632281ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565af66f-30b4-41b4-a49f-88b7bbfc6fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2çš„å‚æ•°èŒƒå›´ä»70äº¿åˆ°700äº¿ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"llama2æœ‰å¤šå°‘å‚æ•°\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4c617-2fb8-489d-a0d0-34d5ca196f1c",
   "metadata": {},
   "source": [
    "## 2ã€LlamaIndex ä»‹ç»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313487e1-a2c7-4d4b-ad41-e3a9f0a0b07e",
   "metadata": {},
   "source": [
    "_ã€Œ LlamaIndex is a framework for building context-augmented LLM applications. Context augmentation refers to any use case that applies LLMs on top of your private or domain-specific data. ã€_\n",
    "\n",
    "LlamaIndex æ˜¯ä¸€ä¸ªä¸ºå¼€å‘ã€Œä¸Šä¸‹æ–‡å¢å¼ºã€çš„å¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„æ¡†æ¶ï¼ˆä¹Ÿå°±æ˜¯SDKï¼‰ã€‚**ä¸Šä¸‹æ–‡å¢å¼º**ï¼Œæ³›æŒ‡ä»»ä½•åœ¨ç§æœ‰æˆ–ç‰¹å®šé¢†åŸŸæ•°æ®åŸºç¡€ä¸Šåº”ç”¨å¤§è¯­è¨€æ¨¡å‹çš„æƒ…å†µã€‚ä¾‹å¦‚ï¼š\n",
    "\n",
    "\n",
    "- Question-Answering Chatbots (ä¹Ÿå°±æ˜¯ RAG)\n",
    "  \n",
    "- Document Understanding and Extraction ï¼ˆæ–‡æ¡£ç†è§£ä¸ä¿¡æ¯æŠ½å–ï¼‰ \n",
    "\n",
    "- Autonomous Agents that can perform research and take actions ï¼ˆæ™ºèƒ½ä½“åº”ç”¨ï¼‰\n",
    "\n",
    "LlamaIndex æœ‰ Python å’Œ Typescript ä¸¤ä¸ªç‰ˆæœ¬ï¼ŒPython ç‰ˆçš„æ–‡æ¡£ç›¸å¯¹æ›´å®Œå–„ã€‚\n",
    "\n",
    "- Python æ–‡æ¡£åœ°å€ï¼šhttps://docs.llamaindex.ai/en/stable/\n",
    "  \n",
    "- Python API æ¥å£æ–‡æ¡£ï¼šhttps://docs.llamaindex.ai/en/stable/api_reference/\n",
    "\n",
    "- TS æ–‡æ¡£åœ°å€ï¼šhttps://ts.llamaindex.ai/\n",
    "\n",
    "- TS API æ¥å£æ–‡æ¡£ï¼šhttps://ts.llamaindex.ai/api/\n",
    "\n",
    "LlamaIndex æ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/run-llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4822b2-52d5-411c-8244-3432f8733da2",
   "metadata": {},
   "source": [
    "### LlamaIndex çš„æ ¸å¿ƒæ¨¡å—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c474b43-018a-4687-a51e-54b391a6bbca",
   "metadata": {},
   "source": [
    "<img src=\"llamaindex.png\" alt=\"LlamaIndex æ ¸å¿ƒæ¨¡å—\" width=\"600\"/>\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66bf37-48e4-45eb-9e7e-a24e86108ac1",
   "metadata": {},
   "source": [
    "### å®‰è£… LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79027d8d-106f-42c8-b7b6-944a46182bda",
   "metadata": {},
   "source": [
    "1. Python\n",
    "\n",
    "```\n",
    "pip install llama-index\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59179e-c8c8-4730-aa29-01c728c00df4",
   "metadata": {},
   "source": [
    "2. Typescript\n",
    "\n",
    "```\n",
    "# é€šè¿‡ npm å®‰è£…\n",
    "npm install llamaindex\n",
    "\n",
    "# é€šè¿‡ yarn å®‰è£…\n",
    "yarn add llamaindex\n",
    "\n",
    "# é€šè¿‡ pnpm å®‰è£…\n",
    "pnpm add llamaindex\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a882ce-b03f-43dc-aa4c-b269ff49adfd",
   "metadata": {},
   "source": [
    "æœ¬è¯¾ç¨‹ä»¥ Python ç‰ˆä¸ºä¾‹è¿›è¡Œè®²è§£ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74341a28-fb7f-4e5b-9342-cf5cd850654a",
   "metadata": {},
   "source": [
    "## 3ã€æ•°æ®åŠ è½½ï¼ˆLoadingï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d134a56-ae9a-41a5-a703-ce9dfb3fc600",
   "metadata": {},
   "source": [
    "### 3.1ã€åŠ è½½æœ¬åœ°æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35bfa25-9a09-4c40-afa1-9f9156e56dc2",
   "metadata": {},
   "source": [
    "`SimpleDirectoryReader` æ˜¯ä¸€ä¸ªç®€å•çš„æœ¬åœ°æ–‡ä»¶åŠ è½½å™¨ã€‚å®ƒä¼šéå†æŒ‡å®šç›®å½•ï¼Œå¹¶æ ¹æ®æ–‡ä»¶æ‰©å±•åè‡ªåŠ¨åŠ è½½æ–‡ä»¶ï¼ˆ**æ–‡æœ¬å†…å®¹**ï¼‰ã€‚\r\n",
    "\r\n",
    "æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š\r\n",
    "\r\n",
    "- `.csv` - comma-separated values\r\n",
    "- `.docx` - Microsoft Word\r\n",
    "- `.epub` - EPUB ebook format\r\n",
    "- `.hwp` - Hangul Word Processor\r\n",
    "- `.ipynb` - Jupyter Notebook\r\n",
    "- `.jpeg`, `.jpg` - JPEG image\r\n",
    "- `.mbox` - MBOX email archive\r\n",
    "- `.md` - Markdown\r\n",
    "- `.mp3`, `.mp4` - audio and video\r\n",
    "- `.pdf` - Portable Document Format\r\n",
    "- `.png` - Portable Network Graphics\r\n",
    "- `.ppt`, `.pptm`, `.pptx` - Microsoft PowerPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b6a279-3eca-4685-af91-80fb443fca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic.v1 import BaseModel\n",
    "\n",
    "def show_json(data):\n",
    "    \"\"\"ç”¨äºå±•ç¤ºjsonæ•°æ®\"\"\"\n",
    "    if isinstance(data, str):\n",
    "        obj = json.loads(data)\n",
    "        print(json.dumps(obj, indent=4))\n",
    "    elif isinstance(data, dict) or isinstance(data, list):\n",
    "        print(json.dumps(data, indent=4))\n",
    "    elif issubclass(type(data), BaseModel):\n",
    "        print(json.dumps(data.dict(), indent=4, ensure_ascii=False))\n",
    "\n",
    "def show_list_obj(data):\n",
    "    \"\"\"ç”¨äºå±•ç¤ºä¸€ç»„å¯¹è±¡\"\"\"\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            show_json(item)\n",
    "    else:\n",
    "        raise ValueError(\"Input is not a list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "198ebc20-fab6-46a9-8cca-4b114fe2640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "        input_dir=\"./data\", # ç›®æ ‡ç›®å½•\n",
    "        recursive=False, # æ˜¯å¦é€’å½’éå†å­ç›®å½•\n",
    "        required_exts=[\".pdf\"] # (å¯é€‰)åªè¯»å–æŒ‡å®šåç¼€çš„æ–‡ä»¶\n",
    "    )\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb3f1ac-75cb-4c5e-b0a1-53621d8d325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id_\": \"e5f96b3c-2a5b-45dc-8ceb-28d18a588fc1\",\n",
      "    \"embedding\": null,\n",
      "    \"metadata\": {\n",
      "        \"page_label\": \"1\",\n",
      "        \"file_name\": \"llama2-extracted.pdf\",\n",
      "        \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "        \"file_type\": \"application/pdf\",\n",
      "        \"file_size\": 401338,\n",
      "        \"creation_date\": \"2024-06-14\",\n",
      "        \"last_modified_date\": \"2024-06-14\"\n",
      "    },\n",
      "    \"excluded_embed_metadata_keys\": [\n",
      "        \"file_name\",\n",
      "        \"file_type\",\n",
      "        \"file_size\",\n",
      "        \"creation_date\",\n",
      "        \"last_modified_date\",\n",
      "        \"last_accessed_date\"\n",
      "    ],\n",
      "    \"excluded_llm_metadata_keys\": [\n",
      "        \"file_name\",\n",
      "        \"file_type\",\n",
      "        \"file_size\",\n",
      "        \"creation_date\",\n",
      "        \"last_modified_date\",\n",
      "        \"last_accessed_date\"\n",
      "    ],\n",
      "    \"relationships\": {},\n",
      "    \"text\": \"Llama 2: OpenFoundation andFine-Tuned ChatModels\\nHugo Touvronâˆ—Louis Martinâ€ Kevin Stoneâ€ \\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov SoumyaBatra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel LukasBlecher Cristian CantonFerrer MoyaChen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu BrianFuller\\nCynthia Gao VedanujGoswami NamanGoyal AnthonyHartshorn Saghar Hosseini RuiHou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa IsabelKloumann ArtemKorenev\\nPunit Singh Koura Marie-AnneLachaux ThibautLavril Jenya Lee Diana Liskovich\\nYinghai Lu YuningMao Xavier Martinet Todor Mihaylov PushkarMishra\\nIgor Molybog Yixin Nie AndrewPoulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva EricMichael Smith Ranjan Subramanian XiaoqingEllenTan BinhTang\\nRoss Taylor AdinaWilliams JianXiang Kuan PuxinXu ZhengYan Iliyan Zarov YuchenZhang\\nAngela Fan MelanieKambadur SharanNarang Aurelien Rodriguez RobertStojnic\\nSergey Edunov ThomasScialomâˆ—\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsibledevelopmentof LLMs.\\nâˆ—Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\nâ€ Second author\\nContributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\",\n",
      "    \"mimetype\": \"text/plain\",\n",
      "    \"start_char_idx\": null,\n",
      "    \"end_char_idx\": null,\n",
      "    \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "    \"metadata_template\": \"{key}: {value}\",\n",
      "    \"metadata_seperator\": \"\\n\",\n",
      "    \"class_name\": \"Document\"\n",
      "}\n",
      "Llama 2: OpenFoundation andFine-Tuned ChatModels\n",
      "Hugo Touvronâˆ—Louis Martinâ€ Kevin Stoneâ€ \n",
      "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov SoumyaBatra\n",
      "Prajjwal Bhargava Shruti Bhosale Dan Bikel LukasBlecher Cristian CantonFerrer MoyaChen\n",
      "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu BrianFuller\n",
      "Cynthia Gao VedanujGoswami NamanGoyal AnthonyHartshorn Saghar Hosseini RuiHou\n",
      "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa IsabelKloumann ArtemKorenev\n",
      "Punit Singh Koura Marie-AnneLachaux ThibautLavril Jenya Lee Diana Liskovich\n",
      "Yinghai Lu YuningMao Xavier Martinet Todor Mihaylov PushkarMishra\n",
      "Igor Molybog Yixin Nie AndrewPoulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
      "Alan Schelten Ruan Silva EricMichael Smith Ranjan Subramanian XiaoqingEllenTan BinhTang\n",
      "Ross Taylor AdinaWilliams JianXiang Kuan PuxinXu ZhengYan Iliyan Zarov YuchenZhang\n",
      "Angela Fan MelanieKambadur SharanNarang Aurelien Rodriguez RobertStojnic\n",
      "Sergey Edunov ThomasScialomâˆ—\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
      "Our fine-tuned LLMs, called Llama 2-Chat , are optimized for dialogue use cases. Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "ourhumanevaluationsforhelpfulnessandsafety,maybeasuitablesubstituteforclosed-\n",
      "source models. We provide a detailed description of our approach to fine-tuning and safety\n",
      "improvements of Llama 2-Chat in order to enable the community to build on our work and\n",
      "contribute to the responsibledevelopmentof LLMs.\n",
      "âˆ—Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\n",
      "â€ Second author\n",
      "Contributions for all the authors can be found in Section A.1.arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\n"
     ]
    }
   ],
   "source": [
    "show_json(documents[0])\n",
    "\n",
    "print(documents[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277be7f4-1993-4b74-bd3e-f9d8cb5a827d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\r\n",
    "<b>æ³¨æ„ï¼š</b>å¯¹å›¾åƒã€è§†é¢‘ã€è¯­éŸ³ç±»æ–‡ä»¶ï¼Œé»˜è®¤ä¸ä¼šè‡ªåŠ¨æå–å…¶ä¸­æ–‡å­—ã€‚å¦‚éœ€æå–ï¼Œå‚è€ƒä¸‹é¢ä»‹ç»çš„ <code>Data Connectors</code>ã€‚\r\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c98851-0858-4215-858d-bea70e310d5f",
   "metadata": {},
   "source": [
    "é»˜è®¤çš„ `PDFReader` æ•ˆæœå¹¶ä¸ç†æƒ³ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ¢æ–‡ä»¶åŠ è½½å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74afcb1d-c832-40b7-bd26-d8d2dc0544f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a81f89-a374-4a27-91bc-f11433b3384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2: Open Foundation and Fine-Tuned Chat Models\n",
      "Hugo Touvronâˆ—\n",
      "Louis Martinâ€ \n",
      "Kevin Stoneâ€ \n",
      "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
      "Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
      "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\n",
      "Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\n",
      "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n",
      "Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\n",
      "Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\n",
      "Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
      "Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\n",
      "Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
      "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
      "Sergey Edunov\n",
      "Thomas Scialomâˆ—\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
      "Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "our human evaluations for helpfulness and safety, may be a suitable substitute for closed-\n",
      "source models. We provide a detailed description of our approach to fine-tuning and safety\n",
      "improvements of Llama 2-Chat in order to enable the community to build on our work and\n",
      "contribute to the responsible development of LLMs.\n",
      "âˆ—Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\n",
      "â€ Second author\n",
      "Contributions for all the authors can be found in Section A.1.\n",
      "arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "        input_dir=\"./data\", # ç›®æ ‡ç›®å½•\n",
    "        recursive=False, # æ˜¯å¦é€’å½’éå†å­ç›®å½•\n",
    "        required_exts=[\".pdf\"], # (å¯é€‰)åªè¯»å–æŒ‡å®šåç¼€çš„æ–‡ä»¶\n",
    "        file_extractor={\".pdf\": PyMuPDFReader()} # æŒ‡å®šç‰¹å®šçš„æ–‡ä»¶åŠ è½½å™¨\n",
    "    )\n",
    "\n",
    "documents = reader.load_data()\n",
    "\n",
    "print(documents[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aea293-3ddc-4a47-971d-2964153d6224",
   "metadata": {},
   "source": [
    "æ›´å¤šçš„ PDF åŠ è½½å™¨è¿˜æœ‰ [`SmartPDFLoader`](https://llamahub.ai/l/readers/llama-index-readers-smart-pdf-loader?from=readers) å’Œ [`LlamaParse`](https://llamahub.ai/l/readers/llama-index-readers-llama-parse?from=readers), äºŒè€…éƒ½æä¾›äº†æ›´ä¸°å¯Œçš„è§£æèƒ½åŠ›ï¼ŒåŒ…æ‹¬è§£æç« èŠ‚ä¸æ®µè½ç»“æ„ç­‰ã€‚ä½†ä¸æ˜¯100%å‡†ç¡®ï¼Œå¶æœ‰æ–‡å­—ä¸¢å¤±æˆ–é”™ä½æƒ…å†µï¼Œå»ºè®®æ ¹æ®è‡ªèº«éœ€æ±‚è¯¦ç»†æµ‹è¯•è¯„ä¼°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116d296-e4a4-4710-a41a-318bbab8ec24",
   "metadata": {},
   "source": [
    "### 3.2ã€Data Connectors\n",
    "\n",
    "ç”¨äºå¤„ç†æ›´ä¸°å¯Œçš„æ•°æ®ç±»å‹ï¼Œå¹¶å°†å…¶è¯»å–ä¸º `Document` çš„å½¢å¼ï¼ˆtext + metadataï¼‰ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼šåŠ è½½ä¸€ä¸ª[é£ä¹¦æ–‡æ¡£](https://agiclass.feishu.cn/docx/FULadzkWmovlfkxSgLPcE4oWnPf)ã€‚ï¼ˆé£ä¹¦æ–‡æ¡£ API è®¿é—®æƒé™ç”³è¯·ï¼Œè¯·å‚è€ƒæ­¤[è¯´æ˜æ–‡æ¡£](é£ä¹¦æ–‡æ¡£ç›¸å…³æƒé™ç”³è¯·.pdf)ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8624b8c-eae0-4499-82b2-0f0c9b17bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index-readers-feishu-docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba285be-d467-406f-8d16-74b3da29fb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI å¤§æ¨¡å‹å…¨æ ˆå·¥ç¨‹å¸ˆåŸ¹å…»è®¡åˆ’ - AGIClass.ai\n",
      "\n",
      "ç”± AGI è¯¾å ‚æ¨å‡ºçš„ç¤¾ç¾¤å‹ä¼šå‘˜åˆ¶è¯¾ç¨‹ï¼Œä¼ æˆå¤§æ¨¡å‹çš„åŸç†ã€åº”ç”¨å¼€å‘æŠ€æœ¯å’Œè¡Œä¸šè®¤çŸ¥ï¼ŒåŠ©ä½ æˆä¸º ChatGPT æµªæ½®ä¸­çš„è¶…çº§ä¸ªä½“\n",
      "ä»€ä¹ˆæ˜¯ AI å¤§æ¨¡å‹å…¨æ ˆå·¥ç¨‹å¸ˆï¼Ÿ\n",
      "ã€ŒAI å¤§æ¨¡å‹å…¨æ ˆå·¥ç¨‹å¸ˆã€ç®€ç§°ã€ŒAI å…¨æ ˆã€ï¼Œæ˜¯ä¸€ä¸ªäººå°±èƒ½å€ŸåŠ© AIï¼Œè®¾è®¡ã€å¼€å‘å’Œè¿è¥åŸºäº AI çš„å¤§æ¨¡å‹åº”ç”¨çš„è¶…çº§ä¸ªä½“ã€‚\n",
      "AI å…¨æ ˆéœ€è¦æ‡‚ä¸šåŠ¡ã€æ‡‚ AIã€æ‡‚ç¼–ç¨‹ï¼Œä¸€ä¸ªäººå°±æ˜¯ä¸€ä¸ªå›¢é˜Ÿï¼Œå•æªåŒ¹é©¬åˆ›é€ è´¢å¯Œã€‚\n",
      "åœ¨æŠ€æœ¯å‹å…¬å¸ï¼ŒAI å…¨æ ˆæœ€æ‡‚ AIï¼Œç¬é—´ç«™ä¸ŠæŠ€æœ¯é¡¶å³°ã€‚\n",
      "åœ¨éæŠ€æœ¯å‹å…¬å¸ï¼ŒAI å…¨æ ˆè¿æ¥å…¶ä»–å‘˜å·¥å’Œ AIï¼Œæå‡æ•´ä¸ªå…¬å¸çš„æ•ˆç‡ã€‚\n",
      "åœ¨å…¬å¸å¤–ï¼ŒAI å…¨æ ˆæ¥é¡¹ç›®ï¼Œç‹¬ç«‹å¼€å‘å˜ç°å°å·¥å…·ï¼Œèµšå–ä¸°åšå‰¯ä¸šæ”¶å…¥ã€‚\n",
      "é€‚åˆäººç¾¤\n",
      "å­¦ä¹ æœ¬è¯¾ç¨‹ï¼Œå¯ä»¥åœ¨ä¸‹è¿°ç›®æ ‡ä¸­ä¸‰é€‰ä¸€ï¼š\n",
      "æˆä¸º AI å…¨æ ˆï¼šæ‡‚ä¸šåŠ¡ã€æ‡‚ AI ä¹Ÿæ‡‚ç¼–ç¨‹ã€‚å¤§é‡ä½¿ç”¨ AIï¼Œè‡ªå·±å®Œæˆ AI åº”ç”¨ä»ç­–åˆ’ã€å¼€å‘åˆ°è½åœ°çš„å…¨è¿‡ç¨‹ã€‚åŒ…æ‹¬å•†ä¸šåˆ†æã€éœ€æ±‚åˆ†æã€äº§å“è®¾è®¡ã€å¼€å‘ã€æµ‹è¯•ã€å¸‚åœºæ¨å¹¿å’Œè¿è¥ç­‰\n",
      "æˆä¸ºä¸šåŠ¡å‘ AI å…¨æ ˆï¼šæ‡‚ä¸šåŠ¡ä¹Ÿæ‡‚ AIï¼Œä¸ç¨‹åºå‘˜åˆä½œï¼Œä¸€èµ·å®Œæˆ AI åº”ç”¨ä»ç­–åˆ’ã€å¼€å‘åˆ°è½åœ°çš„å…¨è¿‡ç¨‹\n",
      "æˆä¸ºç¼–ç¨‹å‘ AI å…¨æ ˆï¼šæ‡‚ç¼–ç¨‹ä¹Ÿæ‡‚ AIï¼Œä¸ä¸šåŠ¡äººå‘˜åˆä½œï¼Œä¸€èµ·å®Œæˆ AI åº”ç”¨ä»ç­–åˆ’ã€å¼€å‘åˆ°è½åœ°çš„å…¨è¿‡ç¨‹\n",
      "æ‡‚è‡³å°‘ä¸€é—¨ç¼–ç¨‹è¯­è¨€ï¼Œå¹¶æœ‰è¿‡çœŸå®é¡¹ç›®å¼€å‘ç»éªŒçš„è½¯ä»¶å¼€å‘â¼¯ç¨‹å¸ˆã€â¾¼çº§â¼¯ç¨‹å¸ˆã€æŠ€æœ¯æ€»ç›‘ã€ç ”å‘ç»ç†ã€æ¶æ„å¸ˆã€æµ‹è¯•â¼¯ç¨‹å¸ˆã€æ•°æ®å·¥ç¨‹å¸ˆã€è¿ç»´å·¥ç¨‹å¸ˆç­‰ï¼Œå»ºè®®ä»¥ã€ŒAI å…¨æ ˆã€ä¸ºç›®æ ‡ã€‚å³ä¾¿å¯¹å•†ä¸šã€äº§å“ã€å¸‚åœºç­‰çš„å­¦ä¹ è¾¾ä¸åˆ°æœ€ä½³ï¼Œä½†å·²æŒæ¡çš„ç»éªŒå’Œè®¤çŸ¥ä¹Ÿæœ‰åŠ©äºæˆä¸ºæœ‰ç«äº‰åŠ›çš„ã€Œç¼–ç¨‹å‘AI å…¨æ ˆã€ã€‚\n",
      "ä¸æ‡‚ç¼–ç¨‹çš„äº§å“ç»ç†ã€éœ€æ±‚åˆ†æå¸ˆã€åˆ›ä¸šè€…ã€è€æ¿ã€è§£å†³æ–¹æ¡ˆå·¥ç¨‹å¸ˆã€é¡¹ç›®ç»ç†ã€è¿è¥ã€å¸‚åœºã€é”€å”®ã€è®¾è®¡å¸ˆç­‰ï¼Œå»ºè®®ä¼˜å…ˆé€‰æ‹©ã€Œä¸šåŠ¡å‘ AI å…¨æ ˆã€ä¸ºç›®æ ‡ã€‚åœ¨è¯¾ç¨‹æä¾›çš„æŠ€æœ¯ç¯å¢ƒé‡Œç†é™¶ï¼Œæé«˜æŠ€æœ¯é¢†åŸŸçš„åˆ¤æ–­åŠ›ï¼Œæœªæ¥å¯ä»¥å’ŒæŠ€æœ¯äººå‘˜æ›´æµç•…åœ°æ²Ÿé€šåä½œã€‚å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œå¦‚æœèƒ½å–„ç”¨ AI å­¦ä¹ ç¼–ç¨‹ã€è¾…åŠ©ç¼–ç¨‹ï¼Œå°±å¯ä»¥å‘ã€ŒAI å…¨æ ˆã€è¿ˆè¿›ã€‚\n",
      "å¸ˆèµ„åŠ›é‡\n",
      "é¦–å¸­è®²å¸ˆ - ç‹å“ç„¶\n",
      "\n",
      "\n",
      "image.png\n",
      "\n",
      "\n",
      "å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦æœ¬ç¡•ï¼Œè‹±å›½ UCL åšå£«ï¼Œå›½é™…çŸ¥åå­¦è€…ã€ä¼ä¸šå®¶ï¼Œå¸ˆä»ç»Ÿè®¡æœºå™¨å­¦ä¹ ç†è®ºå¥ åŸºäººä¹‹ä¸€ John Shawe-Taylor æ•™æˆï¼Œæ˜¯æœ€æ—©ä»äº‹äººæœºå¯¹è¯ç ”ç©¶çš„åè£”å­¦è€…ä¹‹ä¸€ï¼Œè‡³ä»Šå·²è¶… 20 å¹´ã€‚\n",
      "ä»–å°±æ˜¯ AI å…¨æ ˆï¼Œä»åœ¨ç ”å‘ä¸€çº¿ï¼Œå•äººé”€å”®ã€å”®å‰ã€å¼€å‘ã€å®æ–½å…¨æµç¨‹äº¤ä»˜å¤šä¸ªæ•°ç™¾ä¸‡é‡‘é¢ AI é¡¹ç›®ï¼Œå…¨æ ˆå®æˆ˜ç»éªŒ\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.feishu_docs import FeishuDocsReader\n",
    "\n",
    "# è§è¯´æ˜æ–‡æ¡£\n",
    "app_id = \"cli_a6f1c0fa1fd9d00b\"\n",
    "app_secret = \"dMXCTy8DGaty2xn8I858ZbFDFvcqgiep\"\n",
    "\n",
    "# https://agiclass.feishu.cn/docx/FULadzkWmovlfkxSgLPcE4oWnPf\n",
    "# é“¾æ¥æœ€åçš„ \"FULadzkWmovlfkxSgLPcE4oWnPf\" ä¸ºæ–‡æ¡£ ID \n",
    "doc_ids = [\"FULadzkWmovlfkxSgLPcE4oWnPf\"]\n",
    "\n",
    "# å®šä¹‰é£ä¹¦æ–‡æ¡£åŠ è½½å™¨\n",
    "loader = FeishuDocsReader(app_id, app_secret)\n",
    "\n",
    "# åŠ è½½æ–‡æ¡£\n",
    "documents = loader.load_data(document_ids=doc_ids)\n",
    "\n",
    "# æ˜¾ç¤ºå‰1000å­—ç¬¦\n",
    "print(documents[0].text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a88893-01b8-44a1-9bed-e93e60cec328",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>æ›´å¤š Data Connectors</b>\n",
    "    <ul>\n",
    "        <li>å†…ç½®çš„<a href=\"https://llamahub.ai/l/readers/llama-index-readers-file\">æ–‡ä»¶åŠ è½½å™¨</a></li>\n",
    "        <li>è¿æ¥ä¸‰æ–¹æœåŠ¡çš„<a href=\"https://docs.llamaindex.ai/en/stable/module_guides/loading/connector/modules/\">æ•°æ®åŠ è½½å™¨</a>ï¼Œä¾‹å¦‚æ•°æ®åº“</li>\n",
    "        <li>æ›´å¤šåŠ è½½å™¨å¯ä»¥åœ¨ <a href=\"https://llamahub.ai/\">LlamaHub</a> ä¸Šæ‰¾åˆ°</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed8a42-f6fc-430f-9e92-07736e7f359c",
   "metadata": {},
   "source": [
    "## 4ã€æ–‡æœ¬åˆ‡åˆ†ä¸è§£æï¼ˆChunkingï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad7ebd-9e56-47f9-8136-2e1098139c01",
   "metadata": {},
   "source": [
    "ä¸ºæ–¹ä¾¿æ£€ç´¢ï¼Œæˆ‘ä»¬é€šå¸¸æŠŠ `Document` åˆ‡åˆ†ä¸º `Node`ã€‚\n",
    "\n",
    "åœ¨ LlamaIndex ä¸­ï¼Œ`Node` è¢«å®šä¹‰ä¸ºä¸€ä¸ªæ–‡æœ¬çš„ã€Œchunkã€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4881c7d9-9107-4704-b322-d3bc34af96f2",
   "metadata": {},
   "source": [
    "### 4.1ã€ä½¿ç”¨ TextSplitters å¯¹æ–‡æœ¬åšåˆ‡åˆ†\n",
    "\n",
    "ä¾‹å¦‚ï¼š`TokenTextSplitter` æŒ‰æŒ‡å®š token æ•°åˆ‡åˆ†æ–‡æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a083f7-cda9-45d9-be3e-397ce866e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "node_parser = TokenTextSplitter(\n",
    "    chunk_size=100,  # æ¯ä¸ª chunk çš„æœ€å¤§é•¿åº¦\n",
    "    chunk_overlap=50  # chunk ä¹‹é—´é‡å é•¿åº¦ \n",
    ")\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(\n",
    "    documents, show_progress=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5852a21f-a23f-49f3-9a51-d62b8c78d7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id_\": \"859c0fac-b277-41a4-ab92-ba26dd232a35\",\n",
      "    \"embedding\": null,\n",
      "    \"metadata\": {},\n",
      "    \"excluded_embed_metadata_keys\": [],\n",
      "    \"excluded_llm_metadata_keys\": [],\n",
      "    \"relationships\": {\n",
      "        \"1\": {\n",
      "            \"node_id\": \"48795986\",\n",
      "            \"node_type\": \"4\",\n",
      "            \"metadata\": {},\n",
      "            \"hash\": \"ec6392b9b6f9cc124cb091b2e47775ec7243d646647d544c73427ed060026bfb\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        },\n",
      "        \"3\": {\n",
      "            \"node_id\": \"8723e3a5-0bb1-4d66-8366-8d7720d0fb56\",\n",
      "            \"node_type\": \"1\",\n",
      "            \"metadata\": {},\n",
      "            \"hash\": \"fb5e8cc543e4443ee13fa113c0c5d4d0ec3d48b4d0748061e05d0dc9063a3ab3\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        }\n",
      "    },\n",
      "    \"text\": \"OpenAI is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco. Its mission is to develop \\\"safe and beneficial\\\" artificial general intelligence, which it defines as \\\"highly autonomous systems that outperform humans at most economically valuable work\\\". As a leading organization in the ongoing AI boom, OpenAI has developed several large language models, advanced image generation models, and previously, released open-source models. Its release of ChatGPT has been credited\",\n",
      "    \"mimetype\": \"text/plain\",\n",
      "    \"start_char_idx\": 0,\n",
      "    \"end_char_idx\": 543,\n",
      "    \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "    \"metadata_template\": \"{key}: {value}\",\n",
      "    \"metadata_seperator\": \"\\n\",\n",
      "    \"class_name\": \"TextNode\"\n",
      "}\n",
      "{\n",
      "    \"id_\": \"8723e3a5-0bb1-4d66-8366-8d7720d0fb56\",\n",
      "    \"embedding\": null,\n",
      "    \"metadata\": {},\n",
      "    \"excluded_embed_metadata_keys\": [],\n",
      "    \"excluded_llm_metadata_keys\": [],\n",
      "    \"relationships\": {\n",
      "        \"1\": {\n",
      "            \"node_id\": \"48795986\",\n",
      "            \"node_type\": \"4\",\n",
      "            \"metadata\": {},\n",
      "            \"hash\": \"ec6392b9b6f9cc124cb091b2e47775ec7243d646647d544c73427ed060026bfb\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        },\n",
      "        \"2\": {\n",
      "            \"node_id\": \"859c0fac-b277-41a4-ab92-ba26dd232a35\",\n",
      "            \"node_type\": \"1\",\n",
      "            \"metadata\": {},\n",
      "            \"hash\": \"e72168575854761753a16569b272a8427d8f20b2e0f0a1bf8ebc994d3e7cf0c8\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        },\n",
      "        \"3\": {\n",
      "            \"node_id\": \"ebf13cf9-0a36-44dc-bb13-baad485de1bc\",\n",
      "            \"node_type\": \"1\",\n",
      "            \"metadata\": {},\n",
      "            \"hash\": \"2d0279fd4aef89280532cd84cd0267da9edae4bf0e07b29a9b1c3bf125db850a\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        }\n",
      "    },\n",
      "    \"text\": \"outperform humans at most economically valuable work\\\". As a leading organization in the ongoing AI boom, OpenAI has developed several large language models, advanced image generation models, and previously, released open-source models. Its release of ChatGPT has been credited with catalyzing widespread interest in AI.\\nThe organization consists of the non-profit OpenAI, Inc. registered in Delaware and its for-profit subsidiary OpenAI Global, LLC. Microsoft owns roughly 49% of OpenAI's equity, having\",\n",
      "    \"mimetype\": \"text/plain\",\n",
      "    \"start_char_idx\": 267,\n",
      "    \"end_char_idx\": 770,\n",
      "    \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "    \"metadata_template\": \"{key}: {value}\",\n",
      "    \"metadata_seperator\": \"\\n\",\n",
      "    \"class_name\": \"TextNode\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "show_json(nodes[0])\n",
    "show_json(nodes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f56dbf-4247-4a06-a127-2fa1929455f0",
   "metadata": {},
   "source": [
    "LlamaIndex æä¾›äº†ä¸°å¯Œçš„ `TextSplitter`ï¼Œä¾‹å¦‚ï¼š\n",
    "\n",
    "- [`SentenceSplitter`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/sentence_splitter/)ï¼šåœ¨åˆ‡åˆ†æŒ‡å®šé•¿åº¦çš„ chunk åŒæ—¶å°½é‡ä¿è¯å¥å­è¾¹ç•Œä¸è¢«åˆ‡æ–­ï¼›\n",
    "- [`CodeSplitter`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/code/)ï¼šæ ¹æ® ASTï¼ˆç¼–è¯‘å™¨çš„æŠ½è±¡å¥æ³•æ ‘ï¼‰åˆ‡åˆ†ä»£ç ï¼Œä¿è¯ä»£ç åŠŸèƒ½ç‰‡æ®µå®Œæ•´ï¼›\n",
    "- [`SemanticSplitterNodeParser`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/semantic_splitter/)ï¼šæ ¹æ®è¯­ä¹‰ç›¸å…³æ€§å¯¹å°†æ–‡æœ¬åˆ‡åˆ†ä¸ºç‰‡æ®µã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692f9fb-af99-4bf5-9d4e-c745438173d6",
   "metadata": {},
   "source": [
    "### 4.2ã€ä½¿ç”¨ NodeParsers å¯¹æœ‰ç»“æ„çš„æ–‡æ¡£åšè§£æ\n",
    "\n",
    "ä¾‹å¦‚ï¼š`MarkdownNodeParser`è§£æ markdown æ–‡æ¡£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5efb4601-877b-4eea-b05c-8006fbb56d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.file import FlatReader\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from pathlib import Path\n",
    "\n",
    "md_docs = FlatReader().load_data(Path(\"./data/ChatALL.md\"))\n",
    "parser = MarkdownNodeParser()\n",
    "nodes = parser.get_nodes_from_documents(md_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28b895a0-2ad8-4aa2-ae59-96b2674f225d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id_\": \"0ed5fbbd-d70e-486b-b487-804e3156e35e\",\n",
      "    \"embedding\": null,\n",
      "    \"metadata\": {\n",
      "        \"Header_2\": \"åŠŸèƒ½\",\n",
      "        \"filename\": \"ChatALL.md\",\n",
      "        \"extension\": \".md\"\n",
      "    },\n",
      "    \"excluded_embed_metadata_keys\": [],\n",
      "    \"excluded_llm_metadata_keys\": [],\n",
      "    \"relationships\": {\n",
      "        \"1\": {\n",
      "            \"node_id\": \"386535b4-a9e9-46a8-a442-015d1fe25ff4\",\n",
      "            \"node_type\": \"4\",\n",
      "            \"metadata\": {\n",
      "                \"filename\": \"ChatALL.md\",\n",
      "                \"extension\": \".md\"\n",
      "            },\n",
      "            \"hash\": \"45b9149e0039c1ef7fbbd74f96923875505cc77916de48734ba7767f6a16a87e\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        },\n",
      "        \"2\": {\n",
      "            \"node_id\": \"e8e16bc1-f6dd-4020-8ebd-d8a0594c441d\",\n",
      "            \"node_type\": \"1\",\n",
      "            \"metadata\": {\n",
      "                \"Header_2\": \"å±å¹•æˆªå›¾\",\n",
      "                \"filename\": \"ChatALL.md\",\n",
      "                \"extension\": \".md\"\n",
      "            },\n",
      "            \"hash\": \"117d78eb026d9b5f7d4d884e3cf594bfaa98d43f07dd30ff85b196308f1fe890\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        },\n",
      "        \"3\": {\n",
      "            \"node_id\": \"ac40dc8a-1ae4-47aa-8485-15ffa3dfe684\",\n",
      "            \"node_type\": \"1\",\n",
      "            \"metadata\": {\n",
      "                \"Header_2\": \"åŠŸèƒ½\",\n",
      "                \"Header_3\": \"è¿™æ˜¯ä½ å—ï¼Ÿ\"\n",
      "            },\n",
      "            \"hash\": \"f54ac07d417fbcbd606e7cdd3de28c30804e2213218dec2e6157d5037a23e289\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        }\n",
      "    },\n",
      "    \"text\": \"åŠŸèƒ½\\n\\nåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ AI æœºå™¨äººéå¸¸ç¥å¥‡ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„è¡Œä¸ºå¯èƒ½æ˜¯éšæœºçš„ï¼Œä¸åŒçš„æœºå™¨äººåœ¨ä¸åŒçš„ä»»åŠ¡ä¸Šè¡¨ç°ä¹Ÿæœ‰å·®å¼‚ã€‚å¦‚æœä½ æƒ³è·å¾—æœ€ä½³ä½“éªŒï¼Œä¸è¦ä¸€ä¸ªä¸€ä¸ªå°è¯•ã€‚ChatALLï¼ˆä¸­æ–‡åï¼šé½å¨ï¼‰å¯ä»¥æŠŠä¸€æ¡æŒ‡ä»¤åŒæ—¶å‘ç»™å¤šä¸ª AIï¼Œå¸®åŠ©æ‚¨å‘ç°æœ€å¥½çš„å›ç­”ã€‚ä½ éœ€è¦åšçš„åªæ˜¯[ä¸‹è½½ã€å®‰è£…](https://github.com/sunner/ChatALL/releases)å’Œæé—®ã€‚\",\n",
      "    \"mimetype\": \"text/plain\",\n",
      "    \"start_char_idx\": 459,\n",
      "    \"end_char_idx\": 650,\n",
      "    \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "    \"metadata_template\": \"{key}: {value}\",\n",
      "    \"metadata_seperator\": \"\\n\",\n",
      "    \"class_name\": \"TextNode\"\n",
      "}\n",
      "{\n",
      "    \"id_\": \"ac40dc8a-1ae4-47aa-8485-15ffa3dfe684\",\n",
      "    \"embedding\": null,\n",
      "    \"metadata\": {\n",
      "        \"Header_2\": \"åŠŸèƒ½\",\n",
      "        \"Header_3\": \"è¿™æ˜¯ä½ å—ï¼Ÿ\",\n",
      "        \"filename\": \"ChatALL.md\",\n",
      "        \"extension\": \".md\"\n",
      "    },\n",
      "    \"excluded_embed_metadata_keys\": [],\n",
      "    \"excluded_llm_metadata_keys\": [],\n",
      "    \"relationships\": {\n",
      "        \"1\": {\n",
      "            \"node_id\": \"386535b4-a9e9-46a8-a442-015d1fe25ff4\",\n",
      "            \"node_type\": \"4\",\n",
      "            \"metadata\": {\n",
      "                \"filename\": \"ChatALL.md\",\n",
      "                \"extension\": \".md\"\n",
      "            },\n",
      "            \"hash\": \"45b9149e0039c1ef7fbbd74f96923875505cc77916de48734ba7767f6a16a87e\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        },\n",
      "        \"2\": {\n",
      "            \"node_id\": \"0ed5fbbd-d70e-486b-b487-804e3156e35e\",\n",
      "            \"node_type\": \"1\",\n",
      "            \"metadata\": {\n",
      "                \"Header_2\": \"åŠŸèƒ½\",\n",
      "                \"filename\": \"ChatALL.md\",\n",
      "                \"extension\": \".md\"\n",
      "            },\n",
      "            \"hash\": \"e55bca9054a8c81ae48646990ff59a59f34e51dcf11f47e9dbd0a7e1d8e7f1de\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        },\n",
      "        \"3\": {\n",
      "            \"node_id\": \"5d54d722-ee2d-4ee9-839c-3eecbe9f1768\",\n",
      "            \"node_type\": \"1\",\n",
      "            \"metadata\": {\n",
      "                \"Header_2\": \"åŠŸèƒ½\",\n",
      "                \"Header_3\": \"æ”¯æŒçš„ AI\"\n",
      "            },\n",
      "            \"hash\": \"1b2b11abec9fc74b725b6c344f37d44736e8e991a3eebdbcfa4ab682506c7b2e\",\n",
      "            \"class_name\": \"RelatedNodeInfo\"\n",
      "        }\n",
      "    },\n",
      "    \"text\": \"è¿™æ˜¯ä½ å—ï¼Ÿ\\n\\nChatALL çš„å…¸å‹ç”¨æˆ·æ˜¯ï¼š\\n\\n- ğŸ¤ **å¤§æ¨¡å‹é‡åº¦ç©å®¶**ï¼Œå¸Œæœ›ä»å¤§æ¨¡å‹æ‰¾åˆ°æœ€å¥½çš„ç­”æ¡ˆï¼Œæˆ–è€…æœ€å¥½çš„åˆ›ä½œ\\n- ğŸ¤“**å¤§æ¨¡å‹ç ”ç©¶è€…**ï¼Œç›´è§‚æ¯”è¾ƒå„ç§å¤§æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸçš„ä¼˜åŠ£\\n- ğŸ˜**å¤§æ¨¡å‹åº”ç”¨å¼€å‘è€…**ï¼Œå¿«é€Ÿè°ƒè¯• promptï¼Œå¯»æ‰¾è¡¨ç°æœ€ä½³çš„åŸºç¡€æ¨¡å‹\",\n",
      "    \"mimetype\": \"text/plain\",\n",
      "    \"start_char_idx\": 656,\n",
      "    \"end_char_idx\": 788,\n",
      "    \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "    \"metadata_template\": \"{key}: {value}\",\n",
      "    \"metadata_seperator\": \"\\n\",\n",
      "    \"class_name\": \"TextNode\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "show_json(nodes[2])\n",
    "show_json(nodes[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc613c-36a8-4afb-871b-097496703eaf",
   "metadata": {},
   "source": [
    "æ›´å¤šçš„ `NodeParser` åŒ…æ‹¬ [`HTMLNodeParser`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/html/)ï¼Œ[`JSONNodeParser`](https://docs.llamaindex.ai/en/stable/api_reference/node_parsers/json/)ç­‰ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8557f-20af-477d-918d-14761a9c986d",
   "metadata": {},
   "source": [
    "## 5ã€ç´¢å¼•ï¼ˆIndexingï¼‰ä¸æ£€ç´¢ï¼ˆRetrievalï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df338b16-df37-412d-a385-2d1f4b681112",
   "metadata": {},
   "source": [
    "**åŸºç¡€æ¦‚å¿µ**ï¼šåœ¨ã€Œæ£€ç´¢ã€ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œã€Œç´¢å¼•ã€å³`index`ï¼Œ é€šå¸¸æ˜¯æŒ‡ä¸ºäº†å®ç°å¿«é€Ÿæ£€ç´¢è€Œè®¾è®¡çš„ç‰¹å®šã€Œæ•°æ®ç»“æ„ã€ã€‚\n",
    "\n",
    "ç´¢å¼•çš„å…·ä½“åŸç†ä¸å®ç°ä¸æ˜¯æœ¬è¯¾ç¨‹çš„æ•™å­¦é‡ç‚¹ï¼Œæ„Ÿå…´è¶£çš„åŒå­¦å¯ä»¥å‚è€ƒï¼š[ä¼ ç»Ÿç´¢å¼•](https://en.wikipedia.org/wiki/Search_engine_indexing)ã€[å‘é‡ç´¢å¼•](https://medium.com/kx-systems/vector-indexing-a-roadmap-for-vector-databases-65866f07daf5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd397fe-8932-49de-ac37-bed0b585205c",
   "metadata": {},
   "source": [
    "### 5.1ã€å‘é‡æ£€ç´¢\n",
    "\n",
    "1. `SimpleVectorStore` ç›´æ¥åœ¨å†…å­˜ä¸­æ„å»ºä¸€ä¸ª Vector Store å¹¶å»ºç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea17e80-d25c-43ac-b9b5-983c6acb3adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"node\": {\n",
      "        \"id_\": \"0041bf6b-d778-41a3-b675-1a1407d6d658\",\n",
      "        \"embedding\": null,\n",
      "        \"metadata\": {\n",
      "            \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "            \"file_name\": \"llama2-extracted.pdf\",\n",
      "            \"file_type\": \"application/pdf\",\n",
      "            \"file_size\": 401338,\n",
      "            \"creation_date\": \"2024-06-14\",\n",
      "            \"last_modified_date\": \"2024-06-14\",\n",
      "            \"total_pages\": 4,\n",
      "            \"source\": \"4\"\n",
      "        },\n",
      "        \"excluded_embed_metadata_keys\": [\n",
      "            \"file_name\",\n",
      "            \"file_type\",\n",
      "            \"file_size\",\n",
      "            \"creation_date\",\n",
      "            \"last_modified_date\",\n",
      "            \"last_accessed_date\"\n",
      "        ],\n",
      "        \"excluded_llm_metadata_keys\": [\n",
      "            \"file_name\",\n",
      "            \"file_type\",\n",
      "            \"file_size\",\n",
      "            \"creation_date\",\n",
      "            \"last_modified_date\",\n",
      "            \"last_accessed_date\"\n",
      "        ],\n",
      "        \"relationships\": {\n",
      "            \"1\": {\n",
      "                \"node_id\": \"27aa0e7b-ad7e-48ef-84f2-fc7176b2fc14\",\n",
      "                \"node_type\": \"4\",\n",
      "                \"metadata\": {\n",
      "                    \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "                    \"file_name\": \"llama2-extracted.pdf\",\n",
      "                    \"file_type\": \"application/pdf\",\n",
      "                    \"file_size\": 401338,\n",
      "                    \"creation_date\": \"2024-06-14\",\n",
      "                    \"last_modified_date\": \"2024-06-14\",\n",
      "                    \"total_pages\": 4,\n",
      "                    \"source\": \"4\"\n",
      "                },\n",
      "                \"hash\": \"b29837a2e4d3e1e2b226990cb3eb14138fc66be2a51372a68641272c2095519a\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            },\n",
      "            \"2\": {\n",
      "                \"node_id\": \"4ff11829-ae73-466a-9ff7-c3268ae485b6\",\n",
      "                \"node_type\": \"1\",\n",
      "                \"metadata\": {\n",
      "                    \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "                    \"file_name\": \"llama2-extracted.pdf\",\n",
      "                    \"file_type\": \"application/pdf\",\n",
      "                    \"file_size\": 401338,\n",
      "                    \"creation_date\": \"2024-06-14\",\n",
      "                    \"last_modified_date\": \"2024-06-14\",\n",
      "                    \"total_pages\": 4,\n",
      "                    \"source\": \"4\"\n",
      "                },\n",
      "                \"hash\": \"07108bd9b8afa14b2c31a05dbe825ddf1cf5ca4ddcc8bb87eb57ce03045e7bc7\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            },\n",
      "            \"3\": {\n",
      "                \"node_id\": \"5bd74633-059d-462e-b87f-5b8303d4fb7c\",\n",
      "                \"node_type\": \"1\",\n",
      "                \"metadata\": {},\n",
      "                \"hash\": \"726b948dfd9e32d525760994bddb61dbfaba8a0d18d12a3e3a4f9504fbc208fd\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            }\n",
      "        },\n",
      "        \"text\": \"an updated version of Llama 1, trained on a new mix of publicly available data. We also\\nincreased the size of the pretraining corpus by 40%, doubled the context length of the model, and\\nadopted grouped-query attention (Ainslie et al., 2023). We are releasing variants of Llama 2 with\\n7B, 13B, and 70B parameters. We have also trained 34B variants, which we report on in this paper\\nbut are not releasing.Â§\\n2. Llama 2-Chat, a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWe believe that the open release of LLMs, when done safely, will be a net benefit to society. Like all LLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaiman et al., 2023). Testing conducted to date has been in English and has not â€” and could not â€” cover\\nall scenarios. Therefore, before deploying any applications of\",\n",
      "        \"mimetype\": \"text/plain\",\n",
      "        \"start_char_idx\": 752,\n",
      "        \"end_char_idx\": 1714,\n",
      "        \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "        \"metadata_template\": \"{key}: {value}\",\n",
      "        \"metadata_seperator\": \"\\n\",\n",
      "        \"class_name\": \"TextNode\"\n",
      "    },\n",
      "    \"score\": 0.7902534906577295,\n",
      "    \"class_name\": \"NodeWithScore\"\n",
      "}\n",
      "{\n",
      "    \"node\": {\n",
      "        \"id_\": \"e495bef6-126d-4134-9a26-501d83981b1b\",\n",
      "        \"embedding\": null,\n",
      "        \"metadata\": {\n",
      "            \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "            \"file_name\": \"llama2-extracted.pdf\",\n",
      "            \"file_type\": \"application/pdf\",\n",
      "            \"file_size\": 401338,\n",
      "            \"creation_date\": \"2024-06-14\",\n",
      "            \"last_modified_date\": \"2024-06-14\",\n",
      "            \"total_pages\": 4,\n",
      "            \"source\": \"1\"\n",
      "        },\n",
      "        \"excluded_embed_metadata_keys\": [\n",
      "            \"file_name\",\n",
      "            \"file_type\",\n",
      "            \"file_size\",\n",
      "            \"creation_date\",\n",
      "            \"last_modified_date\",\n",
      "            \"last_accessed_date\"\n",
      "        ],\n",
      "        \"excluded_llm_metadata_keys\": [\n",
      "            \"file_name\",\n",
      "            \"file_type\",\n",
      "            \"file_size\",\n",
      "            \"creation_date\",\n",
      "            \"last_modified_date\",\n",
      "            \"last_accessed_date\"\n",
      "        ],\n",
      "        \"relationships\": {\n",
      "            \"1\": {\n",
      "                \"node_id\": \"956e1b05-2959-4ab7-be62-3d308805ea6b\",\n",
      "                \"node_type\": \"4\",\n",
      "                \"metadata\": {\n",
      "                    \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "                    \"file_name\": \"llama2-extracted.pdf\",\n",
      "                    \"file_type\": \"application/pdf\",\n",
      "                    \"file_size\": 401338,\n",
      "                    \"creation_date\": \"2024-06-14\",\n",
      "                    \"last_modified_date\": \"2024-06-14\",\n",
      "                    \"total_pages\": 4,\n",
      "                    \"source\": \"1\"\n",
      "                },\n",
      "                \"hash\": \"3ebf9b8910125e57c9eea78794c6566c0a85081c97dbf7e83a65e5d791bcda57\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            },\n",
      "            \"2\": {\n",
      "                \"node_id\": \"4dfc0624-feac-4cca-89fe-e956ac3bf2ca\",\n",
      "                \"node_type\": \"1\",\n",
      "                \"metadata\": {\n",
      "                    \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "                    \"file_name\": \"llama2-extracted.pdf\",\n",
      "                    \"file_type\": \"application/pdf\",\n",
      "                    \"file_size\": 401338,\n",
      "                    \"creation_date\": \"2024-06-14\",\n",
      "                    \"last_modified_date\": \"2024-06-14\",\n",
      "                    \"total_pages\": 4,\n",
      "                    \"source\": \"1\"\n",
      "                },\n",
      "                \"hash\": \"bf3806ddee17b6020e00e4e722a57980d0c5fc9f813ff437a756c8dd8f44e52f\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            },\n",
      "            \"3\": {\n",
      "                \"node_id\": \"d3cd28ca-2d69-40b7-993b-f63263f4de06\",\n",
      "                \"node_type\": \"1\",\n",
      "                \"metadata\": {},\n",
      "                \"hash\": \"fe31f0ee71493cf072edea470642efdc2be2103b9deb19d3706be19e2d1fef9b\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            }\n",
      "        },\n",
      "        \"text\": \"Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov\\nThomas Scialomâˆ—\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nour human evaluations for helpfulness and safety, may be a suitable substitute for\",\n",
      "        \"mimetype\": \"text/plain\",\n",
      "        \"start_char_idx\": 513,\n",
      "        \"end_char_idx\": 1464,\n",
      "        \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "        \"metadata_template\": \"{key}: {value}\",\n",
      "        \"metadata_seperator\": \"\\n\",\n",
      "        \"class_name\": \"TextNode\"\n",
      "    },\n",
      "    \"score\": 0.7890007200916708,\n",
      "    \"class_name\": \"NodeWithScore\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "# åŠ è½½ pdf æ–‡æ¡£\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"./data\", \n",
    "    required_exts=[\".pdf\"],\n",
    "    file_extractor={\".pdf\": PyMuPDFReader()}\n",
    ").load_data()\n",
    "\n",
    "# å®šä¹‰ Node Parser\n",
    "node_parser = TokenTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "\n",
    "# åˆ‡åˆ†æ–‡æ¡£\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# æ„å»º index\n",
    "index = VectorStoreIndex(nodes)\n",
    "\n",
    "# è·å– retriever\n",
    "vector_retriever = index.as_retriever(\n",
    "    similarity_top_k=2 # è¿”å›å‰ä¸¤ä¸ªç»“æœ\n",
    ")\n",
    "\n",
    "# æ£€ç´¢\n",
    "results = vector_retriever.retrieve(\"Llama2æœ‰å¤šå°‘å‚æ•°\")\n",
    "\n",
    "show_list_obj(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeca7fd-5606-45a4-8443-ddab6b9e413f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<p>LlamaIndex é»˜è®¤çš„ Embedding æ¨¡å‹æ˜¯ <code>OpenAIEmbedding(model=\"text-embedding-ada-002\")</code>ã€‚</p>\n",
    "<p>å¦‚ä½•æ›¿æ¢æŒ‡å®šçš„ Embedding æ¨¡å‹è§åé¢ç« èŠ‚è¯¦è§£ã€‚</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebec20-7c12-4d2d-a4f4-5cb2abcc5f32",
   "metadata": {},
   "source": [
    "2. ä½¿ç”¨è‡ªå®šä¹‰çš„ Vector Storeï¼Œä»¥ `Chroma` ä¸ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fe2ca84-6fbe-46a6-ae3f-d1646f724a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44808855-9236-4c44-9ea0-8e3eaeb3839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "if os.environ.get('CUR_ENV_IS_STUDENT','false')=='true':\n",
    "    __import__('pysqlite3')\n",
    "    import sys\n",
    "    sys.modules['sqlite3']= sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f3299a-c253-4ddb-b047-ad6dcdf8bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# åˆ›å»º Chroma Client\n",
    "# EphemeralClient åœ¨å†…å­˜åˆ›å»ºï¼›å¦‚æœéœ€è¦å­˜ç›˜ï¼Œå¯ä»¥ä½¿ç”¨ PersistentClient\n",
    "chroma_client = chromadb.EphemeralClient(settings=Settings(allow_reset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2888d988-2cb9-41d7-bbbc-368f6b84c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"node\": {\n",
      "        \"id_\": \"0041bf6b-d778-41a3-b675-1a1407d6d658\",\n",
      "        \"embedding\": null,\n",
      "        \"metadata\": {\n",
      "            \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "            \"file_name\": \"llama2-extracted.pdf\",\n",
      "            \"file_type\": \"application/pdf\",\n",
      "            \"file_size\": 401338,\n",
      "            \"creation_date\": \"2024-06-14\",\n",
      "            \"last_modified_date\": \"2024-06-14\",\n",
      "            \"total_pages\": 4,\n",
      "            \"source\": \"4\"\n",
      "        },\n",
      "        \"excluded_embed_metadata_keys\": [\n",
      "            \"file_name\",\n",
      "            \"file_type\",\n",
      "            \"file_size\",\n",
      "            \"creation_date\",\n",
      "            \"last_modified_date\",\n",
      "            \"last_accessed_date\"\n",
      "        ],\n",
      "        \"excluded_llm_metadata_keys\": [\n",
      "            \"file_name\",\n",
      "            \"file_type\",\n",
      "            \"file_size\",\n",
      "            \"creation_date\",\n",
      "            \"last_modified_date\",\n",
      "            \"last_accessed_date\"\n",
      "        ],\n",
      "        \"relationships\": {\n",
      "            \"1\": {\n",
      "                \"node_id\": \"27aa0e7b-ad7e-48ef-84f2-fc7176b2fc14\",\n",
      "                \"node_type\": \"4\",\n",
      "                \"metadata\": {\n",
      "                    \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "                    \"file_name\": \"llama2-extracted.pdf\",\n",
      "                    \"file_type\": \"application/pdf\",\n",
      "                    \"file_size\": 401338,\n",
      "                    \"creation_date\": \"2024-06-14\",\n",
      "                    \"last_modified_date\": \"2024-06-14\",\n",
      "                    \"total_pages\": 4,\n",
      "                    \"source\": \"4\"\n",
      "                },\n",
      "                \"hash\": \"b29837a2e4d3e1e2b226990cb3eb14138fc66be2a51372a68641272c2095519a\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            },\n",
      "            \"2\": {\n",
      "                \"node_id\": \"4ff11829-ae73-466a-9ff7-c3268ae485b6\",\n",
      "                \"node_type\": \"1\",\n",
      "                \"metadata\": {\n",
      "                    \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "                    \"file_name\": \"llama2-extracted.pdf\",\n",
      "                    \"file_type\": \"application/pdf\",\n",
      "                    \"file_size\": 401338,\n",
      "                    \"creation_date\": \"2024-06-14\",\n",
      "                    \"last_modified_date\": \"2024-06-14\",\n",
      "                    \"total_pages\": 4,\n",
      "                    \"source\": \"4\"\n",
      "                },\n",
      "                \"hash\": \"07108bd9b8afa14b2c31a05dbe825ddf1cf5ca4ddcc8bb87eb57ce03045e7bc7\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            },\n",
      "            \"3\": {\n",
      "                \"node_id\": \"5bd74633-059d-462e-b87f-5b8303d4fb7c\",\n",
      "                \"node_type\": \"1\",\n",
      "                \"metadata\": {},\n",
      "                \"hash\": \"726b948dfd9e32d525760994bddb61dbfaba8a0d18d12a3e3a4f9504fbc208fd\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            }\n",
      "        },\n",
      "        \"text\": \"an updated version of Llama 1, trained on a new mix of publicly available data. We also\\nincreased the size of the pretraining corpus by 40%, doubled the context length of the model, and\\nadopted grouped-query attention (Ainslie et al., 2023). We are releasing variants of Llama 2 with\\n7B, 13B, and 70B parameters. We have also trained 34B variants, which we report on in this paper\\nbut are not releasing.Â§\\n2. Llama 2-Chat, a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWe believe that the open release of LLMs, when done safely, will be a net benefit to society. Like all LLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaiman et al., 2023). Testing conducted to date has been in English and has not â€” and could not â€” cover\\nall scenarios. Therefore, before deploying any applications of\",\n",
      "        \"mimetype\": \"text/plain\",\n",
      "        \"start_char_idx\": 752,\n",
      "        \"end_char_idx\": 1714,\n",
      "        \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "        \"metadata_template\": \"{key}: {value}\",\n",
      "        \"metadata_seperator\": \"\\n\",\n",
      "        \"class_name\": \"TextNode\"\n",
      "    },\n",
      "    \"score\": 0.6573636358924372,\n",
      "    \"class_name\": \"NodeWithScore\"\n",
      "}\n",
      "{\n",
      "    \"node\": {\n",
      "        \"id_\": \"e495bef6-126d-4134-9a26-501d83981b1b\",\n",
      "        \"embedding\": null,\n",
      "        \"metadata\": {\n",
      "            \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "            \"file_name\": \"llama2-extracted.pdf\",\n",
      "            \"file_type\": \"application/pdf\",\n",
      "            \"file_size\": 401338,\n",
      "            \"creation_date\": \"2024-06-14\",\n",
      "            \"last_modified_date\": \"2024-06-14\",\n",
      "            \"total_pages\": 4,\n",
      "            \"source\": \"1\"\n",
      "        },\n",
      "        \"excluded_embed_metadata_keys\": [\n",
      "            \"file_name\",\n",
      "            \"file_type\",\n",
      "            \"file_size\",\n",
      "            \"creation_date\",\n",
      "            \"last_modified_date\",\n",
      "            \"last_accessed_date\"\n",
      "        ],\n",
      "        \"excluded_llm_metadata_keys\": [\n",
      "            \"file_name\",\n",
      "            \"file_type\",\n",
      "            \"file_size\",\n",
      "            \"creation_date\",\n",
      "            \"last_modified_date\",\n",
      "            \"last_accessed_date\"\n",
      "        ],\n",
      "        \"relationships\": {\n",
      "            \"1\": {\n",
      "                \"node_id\": \"956e1b05-2959-4ab7-be62-3d308805ea6b\",\n",
      "                \"node_type\": \"4\",\n",
      "                \"metadata\": {\n",
      "                    \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "                    \"file_name\": \"llama2-extracted.pdf\",\n",
      "                    \"file_type\": \"application/pdf\",\n",
      "                    \"file_size\": 401338,\n",
      "                    \"creation_date\": \"2024-06-14\",\n",
      "                    \"last_modified_date\": \"2024-06-14\",\n",
      "                    \"total_pages\": 4,\n",
      "                    \"source\": \"1\"\n",
      "                },\n",
      "                \"hash\": \"3ebf9b8910125e57c9eea78794c6566c0a85081c97dbf7e83a65e5d791bcda57\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            },\n",
      "            \"2\": {\n",
      "                \"node_id\": \"4dfc0624-feac-4cca-89fe-e956ac3bf2ca\",\n",
      "                \"node_type\": \"1\",\n",
      "                \"metadata\": {\n",
      "                    \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "                    \"file_name\": \"llama2-extracted.pdf\",\n",
      "                    \"file_type\": \"application/pdf\",\n",
      "                    \"file_size\": 401338,\n",
      "                    \"creation_date\": \"2024-06-14\",\n",
      "                    \"last_modified_date\": \"2024-06-14\",\n",
      "                    \"total_pages\": 4,\n",
      "                    \"source\": \"1\"\n",
      "                },\n",
      "                \"hash\": \"bf3806ddee17b6020e00e4e722a57980d0c5fc9f813ff437a756c8dd8f44e52f\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            },\n",
      "            \"3\": {\n",
      "                \"node_id\": \"d3cd28ca-2d69-40b7-993b-f63263f4de06\",\n",
      "                \"node_type\": \"1\",\n",
      "                \"metadata\": {},\n",
      "                \"hash\": \"fe31f0ee71493cf072edea470642efdc2be2103b9deb19d3706be19e2d1fef9b\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            }\n",
      "        },\n",
      "        \"text\": \"Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov\\nThomas Scialomâˆ—\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nour human evaluations for helpfulness and safety, may be a suitable substitute for\",\n",
      "        \"mimetype\": \"text/plain\",\n",
      "        \"start_char_idx\": 513,\n",
      "        \"end_char_idx\": 1464,\n",
      "        \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "        \"metadata_template\": \"{key}: {value}\",\n",
      "        \"metadata_seperator\": \"\\n\",\n",
      "        \"class_name\": \"TextNode\"\n",
      "    },\n",
      "    \"score\": 0.6557350224549295,\n",
      "    \"class_name\": \"NodeWithScore\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "chroma_client.reset() # ä¸ºæ¼”ç¤ºæ–¹ä¾¿ï¼Œå®é™…ä¸ç”¨æ¯æ¬¡ reset\n",
    "chroma_collection = chroma_client.create_collection(\"demo\")\n",
    "\n",
    "# åˆ›å»º Vector Store\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "# Storage Context æ˜¯ Vector Store çš„å­˜å‚¨å®¹å™¨ï¼Œç”¨äºå­˜å‚¨æ–‡æœ¬ã€indexã€å‘é‡ç­‰æ•°æ®\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# åˆ›å»º indexï¼šé€šè¿‡ Storage Context å…³è”åˆ°è‡ªå®šä¹‰çš„ Vector Store\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "\n",
    "# è·å– retriever\n",
    "vector_retriever = index.as_retriever(similarity_top_k=2)\n",
    "\n",
    "# æ£€ç´¢\n",
    "results = vector_retriever.retrieve(\"Llama2æœ‰å¤šå°‘å‚æ•°\")\n",
    "\n",
    "show_list_obj(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913e5d5-7c84-4833-b21d-2fe440749a63",
   "metadata": {},
   "source": [
    "### 5.2ã€æ›´å¤šç´¢å¼•ä¸æ£€ç´¢æ–¹å¼\n",
    "\n",
    "LlamaIndex å†…ç½®äº†ä¸°å¯Œçš„æ£€ç´¢æœºåˆ¶ï¼Œä¾‹å¦‚ï¼š\n",
    "\n",
    "- å…³é”®å­—æ£€ç´¢\n",
    "    - [`BM25Retriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/bm25/)ï¼šåŸºäº tokenizer å®ç°çš„ BM25 ç»å…¸æ£€ç´¢ç®—æ³•\n",
    "    - [`KeywordTableGPTRetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/keyword/#llama_index.core.indices.keyword_table.retrievers.KeywordTableGPTRetriever)ï¼šä½¿ç”¨ GPT æå–æ£€ç´¢å…³é”®å­—\n",
    "    - [`KeywordTableSimpleRetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/keyword/#llama_index.core.indices.keyword_table.retrievers.KeywordTableSimpleRetriever)ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ£€ç´¢å…³é”®å­—\n",
    "    - [`KeywordTableRAKERetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/keyword/#llama_index.core.indices.keyword_table.retrievers.KeywordTableRAKERetriever)ï¼šä½¿ç”¨[`RAKE`](https://pypi.org/project/rake-nltk/)ç®—æ³•æå–æ£€ç´¢å…³é”®å­—ï¼ˆæœ‰è¯­è¨€é™åˆ¶ï¼‰\n",
    " \n",
    "- RAG-Fusion [`QueryFusionRetriever`](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/query_fusion/)\n",
    "\n",
    "- è¿˜æ”¯æŒ [KnowledgeGraph](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/knowledge_graph/)ã€[SQL](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/sql/#llama_index.core.retrievers.SQLRetriever)ã€[Text-to-SQL](https://docs.llamaindex.ai/en/stable/api_reference/retrievers/sql/#llama_index.core.retrievers.NLSQLRetriever) ç­‰ç­‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614cdf54-94a8-49db-b731-34fcc394b001",
   "metadata": {},
   "source": [
    "### 5.3ã€Ingestion Pipeline è‡ªå®šä¹‰æ•°æ®å¤„ç†æµç¨‹\r\n",
    "LlamaIndex é€šè¿‡ `Transformations` å®šä¹‰ä¸€ä¸ªæ•°æ®ï¼ˆ`Documents`ï¼‰çš„å¤šæ­¥å¤„ç†çš„æµç¨‹ï¼ˆPipelineï¼‰ã€‚\n",
    "è¿™ä¸ª Pipeline çš„ä¸€ä¸ªæ˜¾è‘—ç‰¹ç‚¹æ˜¯ï¼Œ**å®ƒçš„æ¯ä¸ªå­æ­¥éª¤æ˜¯å¯ä»¥ç¼“å­˜ï¼ˆcacheï¼‰çš„**ï¼Œå³å¦‚æœè¯¥å­æ­¥éª¤çš„è¾“å…¥ä¸å¤„ç†æ–¹æ³•ä¸å˜ï¼Œé‡å¤è°ƒç”¨æ—¶ä¼šç›´æ¥ä»ç¼“å­˜ä¸­è·å–ç»“æœï¼Œè€Œæ— éœ€é‡æ–°æ‰§è¡Œè¯¥å­æ­¥éª¤ï¼Œè¿™æ ·å³èŠ‚çœæ—¶é—´ä¹Ÿä¼šèŠ‚çœ token ï¼ˆå¦‚æœå­æ­¥éª¤æ¶‰åŠå¤§æ¨¡å‹è°ƒç”¨ï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67cb4df5-13cf-4813-8e0c-21a241714a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.end = time.time()\n",
    "        self.interval = self.end - self.start\n",
    "        print(f\"è€—æ—¶ {self.interval*1000} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9fc3db0-5358-4a8f-9796-ae8c60698bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.03it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  5.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è€—æ—¶ 9421.632051467896 ms\n",
      "{\n",
      "    \"node\": {\n",
      "        \"id_\": \"5ba8006d-6e04-4fe4-9a5a-9ac2f6a8bafd\",\n",
      "        \"embedding\": null,\n",
      "        \"metadata\": {\n",
      "            \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "            \"file_name\": \"llama2-extracted.pdf\",\n",
      "            \"file_type\": \"application/pdf\",\n",
      "            \"file_size\": 401338,\n",
      "            \"creation_date\": \"2024-06-14\",\n",
      "            \"last_modified_date\": \"2024-06-14\",\n",
      "            \"total_pages\": 4,\n",
      "            \"source\": \"1\",\n",
      "            \"document_title\": \"Advancements in Natural Language Processing: Collaborative Efforts in Developing Open Foundation and Fine-Tuned Chat Models, Llama 2, and Improved Safety in Dialogue Systems\"\n",
      "        },\n",
      "        \"excluded_embed_metadata_keys\": [\n",
      "            \"file_name\",\n",
      "            \"file_type\",\n",
      "            \"file_size\",\n",
      "            \"creation_date\",\n",
      "            \"last_modified_date\",\n",
      "            \"last_accessed_date\"\n",
      "        ],\n",
      "        \"excluded_llm_metadata_keys\": [\n",
      "            \"file_name\",\n",
      "            \"file_type\",\n",
      "            \"file_size\",\n",
      "            \"creation_date\",\n",
      "            \"last_modified_date\",\n",
      "            \"last_accessed_date\"\n",
      "        ],\n",
      "        \"relationships\": {\n",
      "            \"1\": {\n",
      "                \"node_id\": \"f56cebf0-1691-425a-852f-6342d2403aed\",\n",
      "                \"node_type\": \"4\",\n",
      "                \"metadata\": {\n",
      "                    \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "                    \"file_name\": \"llama2-extracted.pdf\",\n",
      "                    \"file_type\": \"application/pdf\",\n",
      "                    \"file_size\": 401338,\n",
      "                    \"creation_date\": \"2024-06-14\",\n",
      "                    \"last_modified_date\": \"2024-06-14\",\n",
      "                    \"total_pages\": 4,\n",
      "                    \"source\": \"1\"\n",
      "                },\n",
      "                \"hash\": \"3ebf9b8910125e57c9eea78794c6566c0a85081c97dbf7e83a65e5d791bcda57\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            },\n",
      "            \"2\": {\n",
      "                \"node_id\": \"bc9aba34-428a-48db-b85c-c1c46130a3b1\",\n",
      "                \"node_type\": \"1\",\n",
      "                \"metadata\": {\n",
      "                    \"file_path\": \"/home/jovyan/lecture-notes/07-llamaindex/data/llama2-extracted.pdf\",\n",
      "                    \"file_name\": \"llama2-extracted.pdf\",\n",
      "                    \"file_type\": \"application/pdf\",\n",
      "                    \"file_size\": 401338,\n",
      "                    \"creation_date\": \"2024-06-14\",\n",
      "                    \"last_modified_date\": \"2024-06-14\",\n",
      "                    \"total_pages\": 4,\n",
      "                    \"source\": \"1\"\n",
      "                },\n",
      "                \"hash\": \"7eb01214bbdd65cc7fd9426d23ffe328ef6b519dcd8d0aaa4390105d13bf4cf2\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            },\n",
      "            \"3\": {\n",
      "                \"node_id\": \"4a994164-a76d-4d11-9dc0-d4e130e3cb26\",\n",
      "                \"node_type\": \"1\",\n",
      "                \"metadata\": {},\n",
      "                \"hash\": \"8ef64d99de0d88702a6123c2b128c89a8c9e8931e59e7b5af4872b6db9f1b85c\",\n",
      "                \"class_name\": \"RelatedNodeInfo\"\n",
      "            }\n",
      "        },\n",
      "        \"text\": \"Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov\\nThomas Scialomâˆ—\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nour human evaluations for helpfulness and safety, may be a suitable substitute for closed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\nâˆ—Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\nâ€ Second author\\nContributions for all the authors can be found in Section A.1.\",\n",
      "        \"mimetype\": \"text/plain\",\n",
      "        \"start_char_idx\": 861,\n",
      "        \"end_char_idx\": 1853,\n",
      "        \"text_template\": \"[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n\",\n",
      "        \"metadata_template\": \"{key}: {value}\",\n",
      "        \"metadata_seperator\": \"\\n\",\n",
      "        \"class_name\": \"TextNode\"\n",
      "    },\n",
      "    \"score\": 0.6399676567167574,\n",
      "    \"class_name\": \"NodeWithScore\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply() # åªåœ¨Jupyterç¬”è®°ç¯å¢ƒä¸­éœ€è¦æ­¤æ“ä½œï¼Œå¦åˆ™ä¼šæŠ¥é”™\n",
    "\n",
    "chroma_client.reset() # ä¸ºæ¼”ç¤ºæ–¹ä¾¿ï¼Œå®é™…ä¸ç”¨æ¯æ¬¡ reset\n",
    "chroma_collection = chroma_client.create_collection(\"ingestion_demo\")\n",
    "\n",
    "# åˆ›å»º Vector Store\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=300, chunk_overlap=0), # æŒ‰å¥å­åˆ‡åˆ†\n",
    "        TitleExtractor(), # åˆ©ç”¨ LLM å¯¹æ–‡æœ¬ç”Ÿæˆæ ‡é¢˜\n",
    "        OpenAIEmbedding(), # å°†æ–‡æœ¬å‘é‡åŒ–\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    \"./data\", \n",
    "    required_exts=[\".pdf\"],\n",
    "    file_extractor={\".pdf\": PyMuPDFReader()}\n",
    ").load_data()\n",
    "\n",
    "# è®¡æ—¶\n",
    "with Timer():\n",
    "    # Ingest directly into a vector db\n",
    "    pipeline.run(documents=documents)\n",
    "\n",
    "# åˆ›å»ºç´¢å¼•\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)\n",
    "\n",
    "# è·å– retriever\n",
    "vector_retriever = index.as_retriever(similarity_top_k=1)\n",
    "\n",
    "# æ£€ç´¢\n",
    "results = vector_retriever.retrieve(\"Llama2æœ‰å¤šå°‘å‚æ•°\")\n",
    "\n",
    "show_list_obj(results[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7c552-f195-42b3-b71b-b5fe015cfbdb",
   "metadata": {},
   "source": [
    "æœ¬åœ°ä¿å­˜ `IngestionPipeline` çš„ç¼“å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a64cc297-57a5-4430-a0b5-b4caa46f58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.persist(\"./pipeline_storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf87b939-643a-4129-bea4-d00f5772d0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è€—æ—¶ 37.158966064453125 ms\n"
     ]
    }
   ],
   "source": [
    "new_pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=300, chunk_overlap=0),\n",
    "        TitleExtractor(),\n",
    "        OpenAIEmbedding()\n",
    "    ],\n",
    ")\n",
    "\n",
    "# åŠ è½½ç¼“å­˜\n",
    "new_pipeline.load(\"./pipeline_storage\")\n",
    "\n",
    "with Timer():\n",
    "    nodes = new_pipeline.run(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec928d-fe8b-49b2-85c1-febf16905203",
   "metadata": {},
   "source": [
    "æ­¤å¤–ï¼Œä¹Ÿå¯ä»¥ç”¨è¿œç¨‹çš„ Redis æˆ– MongoDB ç­‰å­˜å‚¨ `IngestionPipeline` çš„ç¼“å­˜ï¼Œå…·ä½“å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼š[Remote Cache Management](https://docs.llamaindex.ai/en/stable/module_guides/loading/ingestion_pipeline/#remote-cache-management)ã€‚\n",
    "\n",
    "`IngestionPipeline` ä¹Ÿæ”¯æŒå¼‚æ­¥å’Œå¹¶å‘è°ƒç”¨ï¼Œè¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼š[Async Support](https://docs.llamaindex.ai/en/stable/module_guides/loading/ingestion_pipeline/#async-support)ã€[Parallel Processing](https://docs.llamaindex.ai/en/stable/module_guides/loading/ingestion_pipeline/#parallel-processing)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53e99b-2ab5-4520-ba96-4a9979a94480",
   "metadata": {},
   "source": [
    "### 5.4ã€æ£€ç´¢åå¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c53c7c-9077-42bc-a5c0-832688b352b8",
   "metadata": {},
   "source": [
    "LlamaIndex çš„ `Node Postprocessors` æä¾›äº†ä¸€ç³»åˆ—æ£€ç´¢åå¤„ç†æ¨¡å—ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼šæˆ‘ä»¬å¯ä»¥ç”¨ä¸åŒæ¨¡å‹å¯¹æ£€ç´¢åçš„ `Nodes` åšé‡æ’åº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7176f29c-be6b-491c-b2e8-6e604ad201b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] There have been public releases of pretrained LLMs\n",
      "(such as BLOOM (Scao et al., 2022), LLaMa-1 (Touvron et al., 2023), and Falcon (Penedo et al., 2023)) that\n",
      "match the performance of closed pretrained competitors like GPT-3 (Brown et al., 2020) and Chinchilla\n",
      "(Hoffmann et al., 2022), but none of these models are suitable substitutes for closed â€œproductâ€ LLMs, such\n",
      "as ChatGPT, BARD, and Claude. These closed product LLMs are heavily fine-tuned to align with human\n",
      "preferences, which greatly enhances their usability and safety. This step can require significant costs in\n",
      "compute and human annotation, and is often not transparent or easily reproducible, limiting progress within\n",
      "the community to advance AI alignment research.\n",
      "In this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and\n",
      "Llama 2-Chat, at scales up to 70B parameters.\n",
      "[1] Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
      "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
      "Sergey Edunov\n",
      "Thomas Scialomâˆ—\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
      "Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "our human evaluations for helpfulness and safety, may be a suitable substitute for closed-\n",
      "source models. We provide a detailed description of our approach to fine-tuning and safety\n",
      "improvements of Llama 2-Chat in order to enable the community to build on our work and\n",
      "contribute to the responsible development of LLMs.\n",
      "âˆ—Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\n",
      "â€ Second author\n",
      "Contributions for all the authors can be found in Section A.1.\n",
      "[2] We have also trained 34B variants, which we report on in this paper\n",
      "but are not releasing.Â§\n",
      "2. Llama 2-Chat, a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\n",
      "variants of this model with 7B, 13B, and 70B parameters as well.\n",
      "We believe that the open release of LLMs, when done safely, will be a net benefit to society. Like all LLMs,\n",
      "Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\n",
      "Solaiman et al., 2023). Testing conducted to date has been in English and has not â€” and could not â€” cover\n",
      "all scenarios. Therefore, before deploying any applications of Llama 2-Chat, developers should perform\n",
      "safety testing and tuning tailored to their specific applications of the model. We provide a responsible use\n",
      "guideÂ¶ and code examplesâ€– to facilitate the safe deployment of Llama 2 and Llama 2-Chat. More details of\n",
      "our responsible release strategy can be found in Section 5.3.\n",
      "[3] Figure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\n",
      "source models. Human raters judged model generations for safety violations across ~2,000 adversarial\n",
      "prompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\n",
      "important to caveat these safety results with the inherent bias of LLM evaluations due to limitations of the\n",
      "prompt set, subjectivity of the review guidelines, and subjectivity of individual raters. Additionally, these\n",
      "safety evaluations are performed using content standards that are likely to be biased towards the Llama\n",
      "2-Chat models.\n",
      "We are releasing the following models to the general public for research and commercial useâ€¡:\n",
      "1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data. We also\n",
      "increased the size of the pretraining corpus by 40%, doubled the context length of the model, and\n",
      "adopted grouped-query attention (Ainslie et al., 2023). We are releasing variants of Llama 2 with\n",
      "7B, 13B, and 70B parameters.\n",
      "[4] . . . . . . . . . . .\n",
      "23\n",
      "4.3\n",
      "Red Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "28\n",
      "4.4\n",
      "Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "29\n",
      "5\n",
      "Discussion\n",
      "32\n",
      "5.1\n",
      "Learnings and Observations . . . . . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "# è·å– retriever\n",
    "vector_retriever = index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "# æ£€ç´¢\n",
    "nodes = vector_retriever.retrieve(\"Llama2 èƒ½å•†ç”¨å—?\")\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    print(f\"[{i}] {node.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db88970-ac74-4942-b03a-5260ff1885a6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "ä»¥ä¸‹ä»£ç ä¸è¦åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œï¼Œä¼šæ­»æœºï¼<br />\n",
    "å¯ä¸‹è½½å·¦ä¾§ rag_demo.py çš„å®Œæ•´ä¾‹å­åœ¨è‡ªå·±æœ¬åœ°è¿è¡Œã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "200d077d-763c-40e1-9c01-3b49267cd667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Figure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed-\n",
      "source models. Human raters judged model generations for safety violations across ~2,000 adversarial\n",
      "prompts consisting of both single and multi-turn prompts. More details can be found in Section 4.4. It is\n",
      "important to caveat these safety results with the inherent bias of LLM evaluations due to limitations of the\n",
      "prompt set, subjectivity of the review guidelines, and subjectivity of individual raters. Additionally, these\n",
      "safety evaluations are performed using content standards that are likely to be biased towards the Llama\n",
      "2-Chat models.\n",
      "We are releasing the following models to the general public for research and commercial useâ€¡:\n",
      "1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data. We also\n",
      "increased the size of the pretraining corpus by 40%, doubled the context length of the model, and\n",
      "adopted grouped-query attention (Ainslie et al., 2023). We are releasing variants of Llama 2 with\n",
      "7B, 13B, and 70B parameters.\n",
      "[1] We have also trained 34B variants, which we report on in this paper\n",
      "but are not releasing.Â§\n",
      "2. Llama 2-Chat, a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\n",
      "variants of this model with 7B, 13B, and 70B parameters as well.\n",
      "We believe that the open release of LLMs, when done safely, will be a net benefit to society. Like all LLMs,\n",
      "Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\n",
      "Solaiman et al., 2023). Testing conducted to date has been in English and has not â€” and could not â€” cover\n",
      "all scenarios. Therefore, before deploying any applications of Llama 2-Chat, developers should perform\n",
      "safety testing and tuning tailored to their specific applications of the model. We provide a responsible use\n",
      "guideÂ¶ and code examplesâ€– to facilitate the safe deployment of Llama 2 and Llama 2-Chat. More details of\n",
      "our responsible release strategy can be found in Section 5.3.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "# æ£€ç´¢åæ’åºæ¨¡å‹\n",
    "postprocessor = SentenceTransformerRerank(\n",
    "    model=\"BAAI/bge-reranker-large\", top_n=2\n",
    ")\n",
    "\n",
    "nodes = postprocessor.postprocess_nodes(nodes, query_str=\"Llama2 èƒ½å•†ç”¨å—?\")\n",
    "\n",
    "for i, node in enumerate(nodes):\n",
    "    print(f\"[{i}] {node.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca41ea-3112-491a-a1a1-5ec8db295b61",
   "metadata": {},
   "source": [
    "æ›´å¤šçš„ Rerank åŠå…¶å®ƒåå¤„ç†æ–¹æ³•ï¼Œå‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼š[Node Postprocessor Modules](https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/node_postprocessors/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d8d69-cd42-445c-a0cd-0dd7c66d07bc",
   "metadata": {},
   "source": [
    "## 6ã€ç”Ÿæˆå›å¤ï¼ˆQA & Chatï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4248c1-602c-4df6-bd6a-72e994faf1ed",
   "metadata": {},
   "source": [
    "### 6.1ã€å•è½®é—®ç­”ï¼ˆQuery Engineï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "261d35c3-8b54-4840-ab88-c04b348b0fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 æ¨¡å‹æœ‰ 7Bã€13B å’Œ 70B å‚æ•°ã€‚\n"
     ]
    }
   ],
   "source": [
    "qa_engine = index.as_query_engine()\n",
    "response = qa_engine.query(\"Llama2 æœ‰å¤šå°‘å‚æ•°?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d55521-5b67-4c26-a8de-440d2e1046a7",
   "metadata": {},
   "source": [
    "#### æµå¼è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1817400e-9311-4161-89e4-507267862524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 æ¨¡å‹æœ‰ 7B, 13B, å’Œ 70B å‚æ•°ã€‚"
     ]
    }
   ],
   "source": [
    "qa_engine = index.as_query_engine(streaming=True)\n",
    "response = qa_engine.query(\"Llama2 æœ‰å¤šå°‘å‚æ•°?\")\n",
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf53205-beb2-4571-81aa-c5f8e12142f5",
   "metadata": {},
   "source": [
    "### 6.2ã€å¤šè½®å¯¹è¯ï¼ˆChat Engineï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81a73a48-469e-4d40-adf3-e0e5ec44305a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama2 æ¨¡å‹æœ‰ 7B, 13B å’Œ 70B å‚æ•°ã€‚\n"
     ]
    }
   ],
   "source": [
    "chat_engine = index.as_chat_engine()\n",
    "response = chat_engine.chat(\"Llama2 æœ‰å¤šå°‘å‚æ•°?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "712c8c71-6420-4c6f-821c-1bd1c31dc8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of parameters in the Llama2 model is 70 billion.\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"How many at most?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3094d188-2241-4995-9704-1d2aeb878e1e",
   "metadata": {},
   "source": [
    "#### æµå¼è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf33effa-ad36-4eea-b1d1-926ca5cc8dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2æœ‰70äº¿åˆ°700äº¿ä¸ªå‚æ•°ã€‚"
     ]
    }
   ],
   "source": [
    "chat_engine = index.as_chat_engine()\n",
    "streaming_response = chat_engine.stream_chat(\"Llama 2æœ‰å¤šå°‘å‚æ•°?\")\n",
    "for token in streaming_response.response_gen:\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb76fa-e4ba-4c47-9785-53eadddf478e",
   "metadata": {},
   "source": [
    "## 7ã€åº•å±‚æ¥å£ï¼šPromptã€LLM ä¸ Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0cce84-9f79-41ef-a6c4-caaeb70d029e",
   "metadata": {},
   "source": [
    "### 7.1ã€Prompt æ¨¡æ¿\n",
    "\n",
    "#### `PromptTemplate` å®šä¹‰æç¤ºè¯æ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41358d83-4fcb-430c-9c2e-c1ac0839cbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å†™ä¸€ä¸ªå…³äºå°æ˜çš„ç¬‘è¯'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\"å†™ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯\")\n",
    "\n",
    "prompt.format(topic=\"å°æ˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a94232-e8d5-4bf2-8751-8851d924fcee",
   "metadata": {},
   "source": [
    "#### `ChatPromptTemplate` å®šä¹‰å¤šè½®æ¶ˆæ¯æ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edb05592-835f-4cb2-bfa0-862796c36fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: ä½ å«ç“œç“œï¼Œä½ å¿…é¡»æ ¹æ®ç”¨æˆ·æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚\n",
      "user: å·²çŸ¥ä¸Šä¸‹æ–‡ï¼š\n",
      "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•\n",
      "\n",
      "é—®é¢˜ï¼šè¿™æ˜¯ä»€ä¹ˆ\n",
      "assistant: \n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "\n",
    "chat_text_qa_msgs = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=\"ä½ å«{name}ï¼Œä½ å¿…é¡»æ ¹æ®ç”¨æˆ·æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚\",\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER, \n",
    "        content=(\n",
    "            \"å·²çŸ¥ä¸Šä¸‹æ–‡ï¼š\\n\" \\\n",
    "            \"{context}\\n\\n\" \\\n",
    "            \"é—®é¢˜ï¼š{question}\"\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "text_qa_template = ChatPromptTemplate(chat_text_qa_msgs)\n",
    "\n",
    "print(\n",
    "    text_qa_template.format(\n",
    "        name=\"ç“œç“œ\",\n",
    "        context=\"è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•\",\n",
    "        question=\"è¿™æ˜¯ä»€ä¹ˆ\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98931d9-f411-4433-9900-649f74a40b6e",
   "metadata": {},
   "source": [
    "### 7.2ã€è¯­è¨€æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1febbfc2-06c1-4692-9ac1-8843e5554098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c0d3842-32ff-4510-9853-47e7282b56e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¥½çš„ï¼Œä»¥ä¸‹æ˜¯ä¸€ä¸ªå…³äºå°æ˜çš„ç¬‘è¯ï¼š\n",
      "\n",
      "å°æ˜çš„è€å¸ˆåœ¨è¯¾å ‚ä¸Šé—®é“ï¼šâ€œåŒå­¦ä»¬ï¼Œå¦‚æœåœ°çƒåœæ­¢è½¬åŠ¨ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿâ€\n",
      "\n",
      "å°æ˜ç«‹åˆ»ä¸¾æ‰‹å›ç­”ï¼šâ€œè€å¸ˆï¼Œé‚£æˆ‘ä»¬å°±ä¼šè¿Ÿåˆ°ï¼â€\n",
      "\n",
      "è€å¸ˆç–‘æƒ‘åœ°é—®ï¼šâ€œä¸ºä»€ä¹ˆä¼šè¿Ÿåˆ°å‘¢ï¼Ÿâ€\n",
      "\n",
      "å°æ˜è‡ªä¿¡æ»¡æ»¡åœ°è¯´ï¼šâ€œå› ä¸ºæˆ‘ä»¬éƒ½åœ¨ç­‰åœ°çƒè½¬å›æ¥å‘€ï¼â€\n",
      "\n",
      "å…¨ç­åŒå­¦å¬äº†éƒ½å“ˆå“ˆå¤§ç¬‘ï¼Œè€å¸ˆä¹Ÿå¿ä¸ä½ç¬‘äº†èµ·æ¥ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = llm.complete(prompt.format(topic=\"å°æ˜\"))\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0cbe1cc-9dfc-4274-8cdd-b4dd6d3eb5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯ç“œç“œï¼Œæˆ‘ä»¬æ­£åœ¨è¿›è¡Œä¸€ä¸ªæµ‹è¯•ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = llm.complete(\n",
    "    text_qa_template.format(\n",
    "        name=\"ç“œç“œ\",\n",
    "        context=\"è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•\",\n",
    "        question=\"ä½ æ˜¯è°ï¼Œæˆ‘ä»¬åœ¨å¹²å˜›\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49f6da-d220-4c36-b697-e3b525902af7",
   "metadata": {},
   "source": [
    "#### è®¾ç½®å…¨å±€ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94943bec-563c-44b5-80bb-9c0a7c05382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = OpenAI(temperature=0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd7b76-2594-4c39-8e81-33e3c985df38",
   "metadata": {},
   "source": [
    "é™¤ OpenAI å¤–ï¼ŒLlamaIndex å·²é›†æˆå¤šä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬äº‘æœåŠ¡ API å’Œæœ¬åœ°éƒ¨ç½² APIï¼Œè¯¦è§å®˜æ–¹æ–‡æ¡£ï¼š[Available LLM integrations](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/modules/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110fc0b-ec6c-445b-a3c2-3ddef41d9589",
   "metadata": {},
   "source": [
    "### 7.3ã€Embedding æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5be1257-eb1a-4e2d-bad9-2cd002841093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# å…¨å±€è®¾å®š\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb025ce6-c065-4cf2-9e9d-5a01f04c26ee",
   "metadata": {},
   "source": [
    "LlamaIndex åŒæ ·é›†æˆäº†å¤šç§ Embedding æ¨¡å‹ï¼ŒåŒ…æ‹¬äº‘æœåŠ¡ API å’Œå¼€æºæ¨¡å‹ï¼ˆHuggingFaceï¼‰ç­‰ï¼Œè¯¦è§[å®˜æ–¹æ–‡æ¡£](https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings/)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91aa7d-6f3a-4387-859c-c7357d7c5d15",
   "metadata": {},
   "source": [
    "## 8ã€åŸºäº LlamaIndex å®ç°ä¸€ä¸ªåŠŸèƒ½è¾ƒå®Œæ•´çš„ RAG ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1b844-605e-4be2-9cae-2e9e56e46b40",
   "metadata": {},
   "source": [
    "åŠŸèƒ½è¦æ±‚ï¼š\n",
    "\n",
    "- åŠ è½½æŒ‡å®šç›®å½•çš„æ–‡ä»¶\n",
    "- æ”¯æŒ RAG-Fusion\n",
    "- ä½¿ç”¨ ChromaDB å‘é‡æ•°æ®åº“ï¼Œå¹¶æŒä¹…åŒ–åˆ°æœ¬åœ°\n",
    "- æ”¯æŒæ£€ç´¢åæ’åº\n",
    "- æ”¯æŒå¤šè½®å¯¹è¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7c710-cd17-4af7-9fbb-179dd211c773",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "ä»¥ä¸‹ä»£ç ä¸è¦åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œï¼Œä¼šæ­»æœºï¼å¯ä¸‹è½½å·¦ä¾§ rag_demo.py åœ¨è‡ªå·±æœ¬åœ°è¿è¡Œã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90348baf-3a5e-4cc4-968d-e90f9d315495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    " \n",
    "# åˆ›å»º ChromaDB å‘é‡æ•°æ®åº“ï¼Œå¹¶æŒä¹…åŒ–åˆ°æœ¬åœ°\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf485f1b-7da4-412e-a121-a7e6b5f3ece9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jovyan/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, KeywordTableIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import time\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply() # åªåœ¨Jupyterç¬”è®°ç¯å¢ƒä¸­éœ€è¦æ­¤æ“ä½œï¼Œå¦åˆ™ä¼šæŠ¥é”™\n",
    "\n",
    "# 1. æŒ‡å®šå…¨å±€llmä¸embeddingæ¨¡å‹\n",
    "Settings.llm = OpenAI(temperature=0, model=\"gpt-4o\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=512)\n",
    "# 2. æŒ‡å®šå…¨å±€æ–‡æ¡£å¤„ç†çš„ Ingestion Pipeline\n",
    "Settings.transformations = [SentenceSplitter(chunk_size=300, chunk_overlap=100)]\n",
    "\n",
    "# 3. åŠ è½½æœ¬åœ°æ–‡æ¡£\n",
    "documents = SimpleDirectoryReader(\"./data\", file_extractor={\".pdf\": PyMuPDFReader()}).load_data()\n",
    "\n",
    "# 4. æ–°å»º collection\n",
    "collection_name = hex(int(time.time()))\n",
    "chroma_collection = chroma_client.get_or_create_collection(collection_name)\n",
    "\n",
    "# 5. åˆ›å»º Vector Store\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "# 6. æŒ‡å®š Vector Store çš„ Storage ç”¨äº index\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")\n",
    "\n",
    "# 7. å®šä¹‰æ£€ç´¢åæ’åºæ¨¡å‹\n",
    "reranker = SentenceTransformerRerank(\n",
    "    model=\"BAAI/bge-reranker-large\", top_n=2\n",
    ")\n",
    "\n",
    "# 8. å®šä¹‰ RAG Fusion æ£€ç´¢å™¨\n",
    "fusion_retriever = QueryFusionRetriever(\n",
    "    [index.as_retriever()],\n",
    "    similarity_top_k=5, # æ£€ç´¢å¬å› top k ç»“æœ\n",
    "    num_queries=3,  # ç”Ÿæˆ query æ•°\n",
    "    use_async=True,\n",
    "    # query_gen_prompt=\"...\",  # å¯ä»¥è‡ªå®šä¹‰ query ç”Ÿæˆçš„ prompt æ¨¡æ¿\n",
    ")\n",
    "\n",
    "# 9. æ„å»ºå•è½® query engine\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    fusion_retriever,\n",
    "    node_postprocessors=[reranker]\n",
    ")\n",
    "\n",
    "# 10. å¯¹è¯å¼•æ“\n",
    "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
    "    query_engine=query_engine, \n",
    "    # condense_question_prompt=... # å¯ä»¥è‡ªå®šä¹‰ chat message prompt æ¨¡æ¿\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0124ef05-eb4b-417b-aa56-7128460162dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: Llama2æœ‰å¤šå°‘å‚æ•°\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Llama 2æœ‰7Bã€13Bå’Œ70Bå‚æ•°çš„å˜ä½“ã€‚\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: æœ€å¤šå¤šå°‘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Llama 2çš„å‚æ•°æœ€å¤šæ˜¯70Bã€‚\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: ChatALLåœ¨å“ªä¸‹è½½\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: ChatALL å¯ä»¥ä» https://github.com/sunner/ChatALL/releases ä¸‹è½½ã€‚\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User: \n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question=input(\"User:\")\n",
    "    if question.strip() == \"\":\n",
    "        break\n",
    "    response = chat_engine.chat(question)\n",
    "    print(f\"AI: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c98c0-6636-4d71-9156-731e7ca28b6f",
   "metadata": {},
   "source": [
    "## LlamaIndex çš„æ›´å¤šåŠŸèƒ½\n",
    "\n",
    "- æ™ºèƒ½ä½“ï¼ˆAgentï¼‰å¼€å‘æ¡†æ¶ï¼šhttps://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/\n",
    "- RAG çš„è¯„æµ‹ï¼šhttps://docs.llamaindex.ai/en/stable/module_guides/evaluating/\n",
    "- è¿‡ç¨‹ç›‘æ§ï¼šhttps://docs.llamaindex.ai/en/stable/module_guides/observability/\n",
    "\n",
    "ä»¥ä¸Šå†…å®¹æ¶‰åŠè¾ƒå¤šèƒŒæ™¯çŸ¥è¯†ï¼Œæš‚æ—¶ä¸åœ¨æœ¬è¯¾å±•å¼€ï¼Œç›¸å…³çŸ¥è¯†ä¼šåœ¨åé¢è¯¾ç¨‹ä¸­é€ä¸€è¯¦ç»†è®²è§£ã€‚\n",
    "\n",
    "æ­¤å¤–ï¼ŒLlamaIndex é’ˆå¯¹ç”Ÿäº§çº§çš„ RAG ç³»ç»Ÿä¸­é‡åˆ°çš„å„ä¸ªæ–¹é¢çš„ç»†èŠ‚é—®é¢˜ï¼Œæ€»ç»“äº†å¾ˆå¤šé«˜ç«¯æŠ€å·§ï¼ˆ[Advanced Topics](https://docs.llamaindex.ai/en/stable/optimizing/production_rag/)ï¼‰ï¼Œå¯¹å®æˆ˜å¾ˆæœ‰å‚è€ƒä»·å€¼ï¼Œéå¸¸æ¨èæœ‰èƒ½åŠ›çš„åŒå­¦é˜…è¯»ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb48e18-b09b-4492-bd5a-d90e6a323e20",
   "metadata": {},
   "source": [
    "## ä½œä¸š\n",
    "\n",
    "1. åŸºäº LlamaIndex å®ç°ä¸€ä¸ªè‡ªå·± RAG ç³»ç»Ÿã€‚\n",
    "2. æŸ¥é˜… LlamaIndex æ–‡æ¡£å’Œç½‘ä¸Šç›¸å…³èµ„æ–™ï¼Œæ€è€ƒå¦‚ä½•è®©ç¬¬8èŠ‚ä¸­çš„ç³»ç»Ÿæ”¯æŒå…³é”®å­—ä¸å‘é‡çš„æ··åˆæ£€ç´¢ï¼ˆé€‰ï¼‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
