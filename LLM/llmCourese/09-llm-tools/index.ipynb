{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ee8ce2-4b03-4b57-b85d-b4fb6db26570",
   "metadata": {},
   "source": [
    "# ğŸ’¡ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbc193-f8fc-4e18-85e7-45d3e8a6383a",
   "metadata": {},
   "source": [
    "1. ç³»ç»Ÿæ€§ç»´æŠ¤ã€æµ‹è¯•ã€ç›‘æ§ä¸€ä¸ª LLM åº”ç”¨\n",
    "2. å­¦ä¹ ä½¿ç”¨ä¸»æµçš„å·¥å…·å®Œæˆä¸Šè¿°å·¥ä½œ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b875f9-faf2-4b87-a4b2-d2ed069a3bd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ğŸ“ è¿™èŠ‚è¯¾æ€ä¹ˆå­¦\n",
    "\n",
    "ä»£ç èƒ½åŠ›è¦æ±‚ï¼š**ä¸­é«˜**ï¼ŒAI/æ•°å­¦åŸºç¡€è¦æ±‚ï¼š**ä½**\n",
    "\n",
    "1. æœ‰ç¼–ç¨‹åŸºç¡€çš„åŒå­¦\n",
    "   - ä»è½¯ä»¶å·¥ç¨‹è§’åº¦ä½“ä¼šä¸€ä¸ª AI åº”ç”¨çš„å¼€å‘ä¸ç»´æŠ¤æµç¨‹\n",
    "2. æ²¡æœ‰ç¼–ç¨‹åŸºç¡€çš„åŒå­¦\n",
    "   - äº†è§£ä¸€ä¸ª AI åº”ç”¨å¼€å‘ä¸ç»´æŠ¤è¿‡ç¨‹ä¸­æ¶‰åŠåˆ°çš„æŠ€æœ¯ä¸é—®é¢˜\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2fb93-5991-48e1-898b-a48ebfda9481",
   "metadata": {},
   "source": [
    "## ç»´æŠ¤ä¸€ä¸ªç”Ÿäº§çº§çš„ LLM åº”ç”¨ï¼Œæˆ‘ä»¬éœ€è¦åšä»€ä¹ˆï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb536c0-3997-457a-b360-62fbbc910454",
   "metadata": {},
   "source": [
    "1. å„ç§æŒ‡æ ‡ç›‘æ§ä¸ç»Ÿè®¡ï¼šè®¿é—®è®°å½•ã€å“åº”æ—¶é•¿ã€Token ç”¨é‡ã€è®¡è´¹ç­‰ç­‰\n",
    "2. è°ƒè¯• Prompt\n",
    "3. æµ‹è¯•/éªŒè¯ç³»ç»Ÿçš„ç›¸å…³è¯„ä¼°æŒ‡æ ‡\n",
    "4. æ•°æ®é›†ç®¡ç†ï¼ˆä¾¿äºå›å½’æµ‹è¯•ï¼‰\n",
    "5. Prompt ç‰ˆæœ¬ç®¡ç†ï¼ˆä¾¿äºå‡çº§/å›æ»šï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579d2ef-95ed-4e05-a025-940434a88100",
   "metadata": {},
   "source": [
    "## é’ˆå¯¹ä»¥ä¸Šéœ€æ±‚ï¼Œæˆ‘ä»¬ä»‹ç»ä¸¤ä¸ªç”Ÿäº§çº§ LLM App ç»´æŠ¤å¹³å°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb8637-fd33-438c-bfba-5acc62ff8500",
   "metadata": {},
   "source": [
    "1. **LangFuse**: å¼€æº + SaaSï¼ˆå…è´¹/ä»˜è´¹ï¼‰ï¼ŒLangSmith å¹³æ›¿ï¼Œå¯é›†æˆ LangChain ä¹Ÿå¯ç›´æ¥å¯¹æ¥ OpenAI APIï¼›\n",
    "2. **LangSmith**: LangChain çš„å®˜æ–¹å¹³å°ï¼ŒSaaS æœåŠ¡ï¼ˆå…è´¹/ä»˜è´¹ï¼‰ï¼Œéå¼€æºï¼Œä¼ä¸šç‰ˆæ”¯æŒç§æœ‰éƒ¨ç½²ï¼›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4068b0-b4bc-42a3-864e-47e019130832",
   "metadata": {},
   "source": [
    "## 1ã€LangFuse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a821ce-8be3-40d2-bb30-7ae9f0e0c7a8",
   "metadata": {},
   "source": [
    "å¼€æºï¼Œæ”¯æŒ LangChain é›†æˆæˆ–åŸç”Ÿ OpenAI API é›†æˆ\n",
    "\n",
    "å®˜æ–¹ç½‘ç«™ï¼šhttps://langfuse.com/\n",
    "\n",
    "é¡¹ç›®åœ°å€ï¼šhttps://github.com/langfuse\n",
    "\n",
    "æ–‡æ¡£åœ°å€ï¼šhttps://langfuse.com/docs\n",
    "\n",
    "APIæ–‡æ¡£ï¼šhttps://api.reference.langfuse.com/\n",
    "\n",
    "  - Python SDK: https://python.reference.langfuse.com/\n",
    "\n",
    "  - JS SDK: https://js.reference.langfuse.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c22be-791e-4c1d-858f-4202a4a51786",
   "metadata": {},
   "source": [
    "1. é€šè¿‡å®˜æ–¹äº‘æœåŠ¡ä½¿ç”¨ï¼š\n",
    "   - æ³¨å†Œ: cloud.langfuse.com\n",
    "   - åˆ›å»º API Key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514461f7-d1c2-4b60-b9e2-1321fa249fe8",
   "metadata": {},
   "source": [
    "```sh\n",
    "LANGFUSE_SECRET_KEY=\"sk-lf-...\"\n",
    "LANGFUSE_PUBLIC_KEY=\"pk-lf-...\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ccf21-e6d5-4269-9930-e936b3d081e1",
   "metadata": {},
   "source": [
    "2. é€šè¿‡ Docker æœ¬åœ°éƒ¨ç½²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a84beb-14f1-466c-bd29-c1dc4d1b9e40",
   "metadata": {},
   "source": [
    "```sh\n",
    "# Clone repository\n",
    "git clone https://github.com/langfuse/langfuse.git\n",
    "cd langfuse\n",
    "\n",
    "# Run server and db\n",
    "docker compose up -d\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4acff-a558-428d-9f3d-0ef64272677c",
   "metadata": {},
   "source": [
    "```sh\n",
    "# åœ¨è‡ªå·±éƒ¨ç½²çš„ç³»ç»Ÿä¸­ç”Ÿæˆä¸Šè¿°ä¸¤ä¸ª KEY\n",
    "# å¹¶åœ¨ç¯å¢ƒå˜é‡ä¸­æŒ‡å®šæœåŠ¡åœ°å€\n",
    "\n",
    "LANGFUSE_SECRET_KEY=\"sk-lf-...\"\n",
    "LANGFUSE_PUBLIC_KEY=\"pk-lf-..\"\n",
    "LANGFUSE_HOST=\"http://localhost:3000\"\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75383b1-fa32-4456-8c58-9ebdd6cf841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44563cbc-a9a0-4f8a-a00a-51e386d74007",
   "metadata": {},
   "source": [
    "### 1.1ã€é€šè¿‡è£…é¥°å™¨è®°å½•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a616c4-a9e1-434d-bebe-6748fca8d5f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World! Nice to meet you!\n"
     ]
    }
   ],
   "source": [
    "from langfuse.decorators import observe\n",
    "from langfuse.openai import openai # OpenAI integration\n",
    " \n",
    "@observe()\n",
    "def run():\n",
    "    return openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": \"å¯¹æˆ‘è¯´Hello, World!\"}\n",
    "        ],\n",
    "    ).choices[0].message.content\n",
    " \n",
    "print(run())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6d934-c517-4481-b593-04aab3389cfd",
   "metadata": {},
   "source": [
    "### 1.1.1ã€å‡ ä¸ªåŸºæœ¬æ¦‚å¿µ\n",
    "\n",
    "- Trace ä¸€èˆ¬è¡¨ç¤ºç”¨æˆ·ä¸ç³»ç»Ÿçš„ä¸€æ¬¡äº¤äº’ï¼Œå…¶ä¸­è®°å½•è¾“å…¥ã€è¾“å‡ºï¼Œä¹ŸåŒ…æ‹¬è‡ªå®šä¹‰çš„ metadata æ¯”å¦‚ç”¨æˆ·åã€session id ç­‰ï¼›\n",
    "- ä¸€ä¸ª trace å†…éƒ¨å¯ä»¥åŒ…å«å¤šä¸ªå­è¿‡ç¨‹ï¼Œè¿™é‡Œå« observarionsï¼›\n",
    "- Observation å¯ä»¥æ˜¯å¤šä¸ªç±»å‹ï¼š\n",
    "  - Event æ˜¯æœ€åŸºæœ¬çš„å•å…ƒï¼Œç”¨äºè®°å½•ä¸€ä¸ª trace ä¸­çš„æ¯ä¸ªäº‹ä»¶ï¼›\n",
    "  - Span è¡¨ä¸€ä¸ª trace ä¸­çš„ä¸€ä¸ª\"è€—æ—¶\"çš„è¿‡ç¨‹ï¼›\n",
    "  - Generation æ˜¯ç”¨äºè®°å½•ä¸ AI æ¨¡å‹äº¤äº’çš„ spanï¼Œä¾‹å¦‚ï¼šè°ƒç”¨ embedding æ¨¡å‹ã€è°ƒç”¨ LLMã€‚\n",
    "- Observation å¯ä»¥åµŒå¥—ä½¿ç”¨ã€‚\n",
    "\n",
    "<img src=\"span.png\" width=600px />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9514a-30d4-4c90-b8e4-78011d7be572",
   "metadata": {},
   "source": [
    "### 1.1.2ã€`observe()` è£…é¥°å™¨çš„å‚æ•°\n",
    "\n",
    "```python\n",
    "def observe(\n",
    "\tself,\n",
    "\t*,\n",
    "\tname: Optional[str] = None, # Trace æˆ– Span çš„åç§°ï¼Œé»˜è®¤ä¸ºå‡½æ•°å\n",
    "\tas_type: Optional[Literal['generation']] = None, # å°†è®°å½•å®šä¹‰ä¸º Observation (LLM è°ƒç”¨ï¼‰\n",
    "\tcapture_input: bool = True, # è®°å½•è¾“å…¥\n",
    "\tcapture_output: bool = True, # è®°å½•è¾“å‡º\n",
    "\ttransform_to_string: Optional[Callable[[Iterable], str]] = None # å°†è¾“å‡ºè½¬ä¸º string\n",
    ") -> Callable[[~F], ~F]:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a5fc71d-508c-454d-aa1f-7554d10acbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World! Nice to meet you! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langfuse.decorators import observe\n",
    "from langfuse.openai import openai # OpenAI integration\n",
    " \n",
    "@observe(name=\"HelloWorld\")\n",
    "def run():\n",
    "    return openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": \"å¯¹æˆ‘è¯´Hello, World!\"}\n",
    "        ],\n",
    "    ).choices[0].message.content\n",
    " \n",
    "print(run())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d845b53f-f62a-4ea7-937a-a0d650b7544d",
   "metadata": {},
   "source": [
    "### 1.1.3ã€é€šè¿‡ `langfuse_context` è®°å½• User IDã€Metadata ç­‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f78b86b-4b0b-49c9-aef6-367d62c7e8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langfuse.decorators import observe, langfuse_context\n",
    "from langfuse.openai import openai # OpenAI integration\n",
    " \n",
    "@observe()\n",
    "def run():\n",
    "    langfuse_context.update_current_trace(\n",
    "        name=\"HelloWorld\",\n",
    "        user_id=\"wzr\",\n",
    "        metadata={\"test\":\"test value\"}\n",
    "    )\n",
    "    return openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": \"å¯¹æˆ‘è¯´Hello, World!\"}\n",
    "        ],\n",
    "    ).choices[0].message.content\n",
    " \n",
    "print(run())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0349c3-75e6-406f-aa45-7477d1557fc3",
   "metadata": {},
   "source": [
    "### 1.2ã€é€šè¿‡ LangChain çš„å›è°ƒé›†æˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f62d06-1ac0-499d-9985-bfcff6d67de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é‡ç½®ç¯å¢ƒï¼Œå¦åˆ™ä¸LangSmithæœ‰å†²çª\n",
    "import os\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"\"\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"\"\n",
    "del openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee41e249-1151-440b-bba0-334cd024b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"Say hello to {input}!\")\n",
    "])\n",
    "\n",
    "\n",
    "# å®šä¹‰è¾“å‡ºè§£æå™¨\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a71703-76d6-450f-9a1c-e0bca46ddde6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello AGIClass! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langfuse.decorators import langfuse_context, observe\n",
    "\n",
    "@observe()\n",
    "def run():\n",
    "    langfuse_context.update_current_trace(\n",
    "            name=\"LangChainDemo\",\n",
    "            user_id=\"wzr\",\n",
    "        )\n",
    "    \n",
    "    # è·å–å½“å‰ LangChain å›è°ƒå¤„ç†å™¨\n",
    "    langfuse_handler = langfuse_context.get_current_langchain_handler()\n",
    "    \n",
    "    return chain.invoke(input=\"AGIClass\", config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "print(run())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a880eb4a-2028-4f6e-a1bf-747cae2e1434",
   "metadata": {},
   "source": [
    "#### æ¢ä¸ªæ¨¡å‹è¯•è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a1f562-aa5a-4ff7-a375-851f3b797e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] [07-04 12:27:34] base.py:624 [t:140414900418368]: This key `stop` does not seem to be a parameter that the model `ERNIE-Bot-turbo` will accept\n",
      "[INFO] [07-04 12:27:34] oauth.py:222 [t:140414900418368]: trying to refresh access_token for ak `cuTPS7***`\n",
      "[INFO] [07-04 12:27:35] oauth.py:237 [t:140414900418368]: sucessfully refresh access_token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç‹å“ç„¶æ‚¨å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥ä¸ºæ‚¨å¸®å¿™çš„å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "# å…¶å®ƒæ¨¡å‹åˆ†è£…åœ¨ langchain_community åº•åŒ…ä¸­\n",
    "from langchain_community.chat_models import QianfanChatEndpoint\n",
    "from langchain_core.messages import HumanMessage\n",
    "import os\n",
    "\n",
    "ernie_model = QianfanChatEndpoint(\n",
    "    qianfan_ak=os.getenv('ERNIE_CLIENT_ID'),\n",
    "    qianfan_sk=os.getenv('ERNIE_CLIENT_SECRET')\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | ernie_model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "@observe()\n",
    "def run():\n",
    "    langfuse_context.update_current_trace(\n",
    "            name=\"ErnieDemo\",\n",
    "            user_id=\"wzr\",\n",
    "        )\n",
    "    \n",
    "    # è·å–å½“å‰ LangChain å›è°ƒå¤„ç†å™¨\n",
    "    langfuse_handler = langfuse_context.get_current_langchain_handler()\n",
    "    \n",
    "    return chain.invoke(input=\"ç‹å“ç„¶\", config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "print(run())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b67f7a-6c4b-4c90-86fa-2f052e732087",
   "metadata": {},
   "source": [
    "### 1.3ã€æ„å»ºä¸€ä¸ªå®é™…åº”ç”¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251ff93-100e-4277-a2ca-e45c3917e999",
   "metadata": {},
   "source": [
    "**AGI è¯¾å ‚è·Ÿè¯¾åŠ©æ‰‹**ï¼Œæ ¹æ®è¯¾ç¨‹å†…å®¹ï¼Œåˆ¤æ–­å­¦ç”Ÿé—®é¢˜æ˜¯å¦éœ€è¦è€å¸ˆè§£ç­”\n",
    "\n",
    "1. åˆ¤æ–­è¯¥é—®é¢˜æ˜¯å¦éœ€è¦è€å¸ˆè§£ç­”ï¼Œå›å¤'Y'æˆ–'N'\n",
    "2. åˆ¤æ–­è¯¥é—®é¢˜æ˜¯å¦å·²æœ‰åŒå­¦é—®è¿‡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e216f6d0-88cb-4bdb-bc1d-3bd932b7d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»º PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "need_answer = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "ä½ æ˜¯AIGCè¯¾ç¨‹çš„åŠ©æ•™ï¼Œä½ çš„å·¥ä½œæ˜¯ä»å­¦å‘˜çš„è¯¾å ‚äº¤æµä¸­é€‰æ‹©å‡ºéœ€è¦è€å¸ˆå›ç­”çš„é—®é¢˜ï¼ŒåŠ ä»¥æ•´ç†ä»¥äº¤ç»™è€å¸ˆå›ç­”ã€‚\n",
    " \n",
    "è¯¾ç¨‹å†…å®¹:\n",
    "{outlines}\n",
    "*********\n",
    "å­¦å‘˜è¾“å…¥:\n",
    "{user_input}\n",
    "*********\n",
    "å¦‚æœè¿™æ˜¯ä¸€ä¸ªéœ€è¦è€å¸ˆç­”ç–‘çš„é—®é¢˜ï¼Œå›å¤Yï¼Œå¦åˆ™å›å¤Nã€‚\n",
    "åªå›å¤Yæˆ–Nï¼Œä¸è¦å›å¤å…¶ä»–å†…å®¹ã€‚\"\"\")\n",
    "\n",
    "check_duplicated = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "å·²æœ‰æé—®åˆ—è¡¨:\n",
    "[\n",
    "{question_list}\n",
    "]\n",
    "*********\n",
    "æ–°æé—®:\n",
    "{user_input}\n",
    "*********\n",
    "å·²æœ‰æé—®åˆ—è¡¨æ˜¯å¦æœ‰å’Œæ–°æé—®ç±»ä¼¼çš„é—®é¢˜? å›å¤Yæˆ–N, Yè¡¨ç¤ºæœ‰ï¼ŒNè¡¨ç¤ºæ²¡æœ‰ã€‚\n",
    "åªå›å¤Yæˆ–Nï¼Œä¸è¦å›å¤å…¶ä»–å†…å®¹ã€‚\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ac9d67-725c-43bc-a08b-cb2e187bd060",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlines = \"\"\"\n",
    "LangChain\n",
    "æ¨¡å‹ I/O å°è£…\n",
    "æ¨¡å‹çš„å°è£…\n",
    "æ¨¡å‹çš„è¾“å…¥è¾“å‡º\n",
    "PromptTemplate\n",
    "OutputParser\n",
    "æ•°æ®è¿æ¥å°è£…\n",
    "æ–‡æ¡£åŠ è½½å™¨ï¼šDocument Loaders\n",
    "æ–‡æ¡£å¤„ç†å™¨\n",
    "å†…ç½®RAGï¼šRetrievalQA\n",
    "è®°å¿†å°è£…ï¼šMemory\n",
    "é“¾æ¶æ„ï¼šChain/LCEL\n",
    "å¤§æ¨¡å‹æ—¶ä»£çš„è½¯ä»¶æ¶æ„ï¼šAgent\n",
    "ReAct\n",
    "SelfAskWithSearch\n",
    "LangServe\n",
    "LangChain.js\n",
    "\"\"\"\n",
    "\n",
    "question_list = [\n",
    "    \"LangChainå¯ä»¥å•†ç”¨å—\",\n",
    "    \"LangChainå¼€æºå—\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15cc8923-701f-4fe9-91e8-68a2cf723880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»º chain\n",
    "model = ChatOpenAI(temperature=0, model_kwargs={\"seed\": 42})\n",
    "parser = StrOutputParser()\n",
    "\n",
    "need_answer_chain = (\n",
    "    need_answer\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "is_duplicated_chain = (\n",
    "    check_duplicated\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a781e6-cd35-4cb3-b9ac-f933bd1c93e2",
   "metadata": {},
   "source": [
    "### 1.3.1ã€ç”¨ Trace è®°å½•ä¸€ä¸ªå¤šæ¬¡è°ƒç”¨ LLM çš„è¿‡ç¨‹\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7753345a-5536-45e2-be95-2c923cb50824",
   "metadata": {},
   "source": [
    "TRACE (id: trace_id)\n",
    "|\n",
    "|-- SPAN: LLMCain (id: generated by Langfuse)\n",
    "|   |\n",
    "|   |-- GENERATION: OpenAI (id: generated by Langfuse)\n",
    "|\n",
    "|-- SPAN: LLMCain (id: generated by 'next_span_id')\n",
    "|   |\n",
    "|   |-- GENERATION: OpenAI (id: generated by Langfuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0de918b2-9e99-479d-8035-f838972ee152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langfuse.decorators import langfuse_context, observe\n",
    "\n",
    "# ä¸»æµç¨‹\n",
    "@observe()\n",
    "def verify_question(\n",
    "    question: str,\n",
    "    outlines: str,\n",
    "    question_list: list,\n",
    "    user_id: str,\n",
    ") -> bool:\n",
    "    langfuse_context.update_current_trace(\n",
    "            name=\"AGIClassAssistant\",\n",
    "            user_id=user_id,\n",
    "        )\n",
    "    \n",
    "    # get the langchain handler for the current trace\n",
    "    langfuse_handler = langfuse_context.get_current_langchain_handler()\n",
    "    # åˆ¤æ–­æ˜¯å¦éœ€è¦å›ç­”\n",
    "    if need_answer_chain.invoke(\n",
    "        {\"user_input\": question, \"outlines\": outlines},\n",
    "        config={\"callbacks\": [langfuse_handler]}\n",
    "    ) == 'Y':\n",
    "        # åˆ¤æ–­æ˜¯å¦ä¸ºé‡å¤é—®é¢˜\n",
    "        if is_duplicated_chain.invoke(\n",
    "            {\"user_input\": question,\n",
    "                \"question_list\": \"\\n\".join(question_list)},\n",
    "            config={\"callbacks\": [langfuse_handler]}\n",
    "        ) == 'N':\n",
    "            question_list.append(question)\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5ff6685-2a26-467b-9a2a-0497833d9162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# å®é™…è°ƒç”¨\n",
    "ret = verify_question(\n",
    "    \"LangChainæ”¯æŒJavaå—\",\n",
    "    # \"è€å¸ˆå¥½\",\n",
    "    outlines,\n",
    "    question_list,\n",
    "    user_id=\"wzr\",\n",
    ")\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb00a3c-11d8-4ff5-be95-7246ba3fc712",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "ä¸Šé¢çš„å®ç°æ˜¯ä¸ºäº†æ¼”ç¤º  trace å’Œ span çš„æ¦‚å¿µã€‚å®é™…ä¸‹é¢çš„å®ç°æ–¹å¼æ›´ä¼˜ã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a0ad402-1646-4a39-bd5a-476441f48331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "\n",
    "cache = {}\n",
    "\n",
    "@observe(as_type=\"generation\")\n",
    "def get_embeddings(text):\n",
    "    '''å°è£… OpenAI çš„ Embedding æ¨¡å‹æ¥å£'''\n",
    "    if text in cache: \n",
    "        # å¦‚æœå·²ç»åœ¨ç¼“å­˜ä¸­ï¼Œä¸å†é‡å¤è°ƒç”¨ï¼ˆèŠ‚çœæ—¶é—´ã€è´¹ç”¨ï¼‰\n",
    "        return cache[text]\n",
    "    data = openai.embeddings.create(\n",
    "        input=[text], \n",
    "        model=\"text-embedding-3-small\",\n",
    "        dimensions=256\n",
    "    ).data\n",
    "    cache[text] = data[0].embedding\n",
    "    return data[0].embedding\n",
    "\n",
    "@observe()\n",
    "def cos_sim(v, m):\n",
    "    '''è®¡ç®—cosineç›¸ä¼¼åº¦'''\n",
    "    score = np.dot(m, v)/(np.linalg.norm(m, axis=1)*np.linalg.norm(v))\n",
    "    return score.tolist()\n",
    "\n",
    "@observe()\n",
    "def check_duplicated(query, existing, threshold=0.825):\n",
    "    '''é€šè¿‡cosineç›¸ä¼¼åº¦é˜ˆå€¼åˆ¤æ–­æ˜¯å¦é‡å¤'''\n",
    "    query_vec = np.array(get_embeddings(query))\n",
    "    mat = np.array([item[1] for item in existing])\n",
    "    cos = cos_sim(query_vec, mat)\n",
    "    return max(cos) >= threshold\n",
    "\n",
    "@observe()\n",
    "def need_answer(question, outlints):\n",
    "    '''åˆ¤æ–­æ˜¯å¦éœ€è¦å›ç­”'''\n",
    "    langfuse_handler = langfuse_context.get_current_langchain_handler()\n",
    "    return need_answer_chain.invoke(\n",
    "        {\"user_input\": question, \"outlines\": outlines},\n",
    "        config={\"callbacks\": [langfuse_handler]}\n",
    "    ) == 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4c02ef6-9dfc-45a0-a1cf-7b2382d324ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡è®¾ å·²æœ‰é—®é¢˜\n",
    "question_list = [\n",
    "    (\"LangChainå¯ä»¥å•†ç”¨å—\", get_embeddings(\"LangChainå¯ä»¥å•†ç”¨å—\")),\n",
    "    (\"LangChainå¼€æºå—\", get_embeddings(\"LangChainå¼€æºå—\")),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c8e794b-334e-45d4-b5ae-e60aeb11e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe()\n",
    "def verify_question(\n",
    "    question: str,\n",
    "    outlines: str,\n",
    "    question_list: list,\n",
    "    user_id,\n",
    ") -> bool:\n",
    "    \n",
    "    langfuse_context.update_current_trace(\n",
    "        name=\"AGIClassAssistant2\",\n",
    "        user_id=user_id,\n",
    "    )\n",
    "    \n",
    "    # åˆ¤æ–­æ˜¯å¦éœ€è¦å›ç­”\n",
    "    if need_answer(question,outlines):\n",
    "        # åˆ¤æ–­æ˜¯å¦é‡å¤\n",
    "        if not check_duplicated(question, question_list):\n",
    "            vec = cache[question]\n",
    "            question_list.append((question,vec))\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f781985c-3159-43ff-a2b3-a4d269fd3685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "ret = verify_question(\n",
    "    \"LangChainæ”¯æŒJavaå—\",\n",
    "    # \"LangChainæœ‰å•†ç”¨è®¸å¯å—\",\n",
    "    outlines,\n",
    "    question_list,\n",
    "    user_id=\"wzr\"\n",
    ")\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb2e27-4c18-424c-99dd-b3c02c29dfcb",
   "metadata": {},
   "source": [
    "### 1.3.2ã€ç”¨ Session è®°å½•ä¸€ä¸ªç”¨æˆ·çš„å¤šè½®å¯¹è¯\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a12e26a6-67b6-4182-ae9b-772551f02cc4",
   "metadata": {},
   "source": [
    "SESSION (id: session_id)\n",
    "|\n",
    "|-- TRACE\n",
    "|-- TRACE\n",
    "|-- TRACE\n",
    "|-- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0c37548-2b93-404e-b4c3-e65d7e9ac019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,  # ç­‰ä»·äºOpenAIæ¥å£ä¸­çš„assistant role\n",
    "    HumanMessage,  # ç­‰ä»·äºOpenAIæ¥å£ä¸­çš„user role\n",
    "    SystemMessage  # ç­‰ä»·äºOpenAIæ¥å£ä¸­çš„system role\n",
    ")\n",
    "from datetime import datetime\n",
    "from langfuse.decorators import langfuse_context, observe\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"ä½ æ˜¯AGIClassçš„è¯¾ç¨‹åŠ©ç†ã€‚\"),\n",
    "]\n",
    "\n",
    "@observe()\n",
    "def chat_one_turn(user_input, user_id, turn_id):\n",
    "    langfuse_context.update_current_trace(\n",
    "        name=f\"ChatTurn{turn_id}\",\n",
    "        user_id=user_id,\n",
    "        session_id=\"chat-\"+now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    )\n",
    "    langfuse_handler = langfuse_context.get_current_langchain_handler()\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    response = llm.invoke(messages, config={\"callbacks\": [langfuse_handler]})\n",
    "    messages.append(response)\n",
    "    return response.content    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cd52c20-e4c6-48af-93c5-ebbc89c82b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  ä½ æ˜¯è°\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: æˆ‘æ˜¯AGIClassçš„è¯¾ç¨‹åŠ©ç†ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  ä½ å¥½\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: ä½ å¥½ï¼æœ‰ä»€ä¹ˆé—®é¢˜æˆ‘å¯ä»¥å¸®åŠ©è§£å†³å‘¢ï¼Ÿ\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  AGIæ˜¯å¹²ä»€ä¹ˆçš„\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: AGIä»£è¡¨äººå·¥é€šç”¨æ™ºèƒ½ï¼Œæ˜¯æŒ‡å…·æœ‰ä¸äººç±»æ™ºèƒ½æ°´å¹³ç›¸å½“çš„æ™ºèƒ½æ°´å¹³çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿã€‚è¿™ç§æ™ºèƒ½ç³»ç»Ÿå°†èƒ½å¤Ÿåœ¨å„ç§ä¸åŒçš„ä»»åŠ¡å’Œé¢†åŸŸä¸­è¿›è¡Œå­¦ä¹ ã€æ¨ç†ã€è§£å†³é—®é¢˜ï¼Œå¹¶è¡¨ç°å‡ºç±»ä¼¼äºäººç±»çš„è®¤çŸ¥èƒ½åŠ›ã€‚AGIçš„æœ€ç»ˆç›®æ ‡æ˜¯åˆ›é€ å‡ºä¸€ä¸ªèƒ½å¤Ÿè‡ªä¸»æ€è€ƒã€å­¦ä¹ å’Œé€‚åº”çš„æ™ºèƒ½ç³»ç»Ÿï¼Œå®ƒå°†æœ‰æ½œåŠ›åœ¨å„ç§é¢†åŸŸå¸¦æ¥æ·±è¿œçš„å½±å“å’Œè¿›æ­¥ã€‚AGIçš„å‘å±•æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦ç ”ç©¶æ–¹å‘ï¼Œä¹Ÿæ˜¯æœªæ¥äººå·¥æ™ºèƒ½å‘å±•çš„å…³é”®ä¹‹ä¸€ã€‚\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  \n"
     ]
    }
   ],
   "source": [
    "user_id=\"wzr\"\n",
    "turn_id = 0\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.strip() == \"\":\n",
    "        break\n",
    "    reply = chat_one_turn(user_input, user_id, turn_id)\n",
    "    print(\"AI: \"+reply)\n",
    "    turn_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c529d3b7-91f2-41fa-a090-04f4746e72d0",
   "metadata": {},
   "source": [
    "### 1.4ã€æ•°æ®é›†ä¸æµ‹è¯•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4507fd3-616e-45be-9d0f-49ae347019b7",
   "metadata": {},
   "source": [
    "### 1.4.1ã€åœ¨çº¿æ ‡æ³¨\n",
    "\n",
    "<img src=\"annotation.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe4c35-fba3-49d9-ae9e-9d2bdffb7b0b",
   "metadata": {},
   "source": [
    "### 1.4.2ã€ä¸Šä¼ å·²æœ‰æ•°æ®é›†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef67abc0-09d9-4548-92e8-158ed23f77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# è°ƒæ•´æ•°æ®æ ¼å¼ {\"input\":{...},\"expected_output\":\"label\"}\n",
    "data = []\n",
    "with open('my_annotations.jsonl', 'r', encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        example = json.loads(line.strip())\n",
    "        item = {\n",
    "            \"input\": {\n",
    "                \"outlines\": example[\"outlines\"],\n",
    "                \"user_input\": example[\"user_input\"]\n",
    "            },\n",
    "            \"expected_output\": example[\"label\"]\n",
    "        }\n",
    "        data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "156368ef-50aa-449f-922b-5a7ffd73f86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:12<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.model import CreateDatasetRequest, CreateDatasetItemRequest\n",
    "from tqdm import tqdm\n",
    "import langfuse\n",
    "\n",
    "\n",
    "dataset_name = \"my-dataset\"\n",
    "\n",
    "# åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
    "langfuse=Langfuse()\n",
    "\n",
    "# åˆ›å»ºæ•°æ®é›†ï¼Œå¦‚æœå·²å­˜åœ¨ä¸ä¼šé‡å¤åˆ›å»º\n",
    "try:\n",
    "    langfuse.create_dataset(\n",
    "        name=dataset_name,\n",
    "        # optional description\n",
    "        description=\"My first dataset\",\n",
    "        # optional metadata\n",
    "        metadata={\n",
    "            \"author\": \"wzr\",\n",
    "            \"type\": \"demo\"\n",
    "        }\n",
    "    )\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# è€ƒè™‘æ¼”ç¤ºè¿è¡Œé€Ÿåº¦ï¼Œåªä¸Šä¼ å‰50æ¡æ•°æ®\n",
    "for item in tqdm(data[:50]):\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=\"my-dataset\",\n",
    "        input=item[\"input\"],\n",
    "        expected_output=item[\"expected_output\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b9e3b-0684-4273-b2af-2919c077b059",
   "metadata": {},
   "source": [
    "### 1.4.3ã€å®šä¹‰è¯„ä¼°å‡½æ•°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6155790-14c6-4931-b8c1-1c8de93538f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_evaluation(output, expected_output):\n",
    "    return output == expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ef8d5-cc46-4350-8c9a-03ab54c08a26",
   "metadata": {},
   "source": [
    "### 1.4.4ã€è¿è¡Œæµ‹è¯•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee1c5a-f3ac-4024-89ab-3d54b877b845",
   "metadata": {},
   "source": [
    "Prompt æ¨¡æ¿ä¸ Chainï¼ˆLCELï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd0c5623-af29-4c3a-b010-75f5b3e4ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "need_answer = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "ä½ æ˜¯AIGCè¯¾ç¨‹çš„åŠ©æ•™ï¼Œä½ çš„å·¥ä½œæ˜¯ä»å­¦å‘˜çš„è¯¾å ‚äº¤æµä¸­é€‰æ‹©å‡ºéœ€è¦è€å¸ˆå›ç­”çš„é—®é¢˜ï¼ŒåŠ ä»¥æ•´ç†ä»¥äº¤ç»™è€å¸ˆå›ç­”ã€‚\n",
    " \n",
    "è¯¾ç¨‹å†…å®¹:\n",
    "{outlines}\n",
    "*********\n",
    "å­¦å‘˜è¾“å…¥:\n",
    "{user_input}\n",
    "*********\n",
    "å¦‚æœè¿™æ˜¯ä¸€ä¸ªéœ€è¦è€å¸ˆç­”ç–‘çš„é—®é¢˜ï¼Œå›å¤Yï¼Œå¦åˆ™å›å¤Nã€‚\n",
    "åªå›å¤Yæˆ–Nï¼Œä¸è¦å›å¤å…¶ä»–å†…å®¹ã€‚\"\"\")\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_kwargs={\"seed\": 42})\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain_v1 = (\n",
    "    need_answer\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3264acb-295c-4aa4-9ea4-9aca340bf52a",
   "metadata": {},
   "source": [
    "åœ¨æ•°æ®é›†ä¸Šæµ‹è¯•æ•ˆæœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fad90f27-5aab-423a-96e8-1dc73a903cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "from langfuse import Langfuse\n",
    "from datetime import datetime\n",
    "\n",
    "langfuse = Langfuse()\n",
    "lock = threading.Lock()\n",
    "\n",
    "def run_evaluation(chain, dataset_name, run_name):\n",
    "    dataset = langfuse.get_dataset(dataset_name)\n",
    "\n",
    "    def process_item(item):\n",
    "        with lock:\n",
    "            handler = item.get_langchain_handler(run_name=run_name)\n",
    "\n",
    "        # Assuming chain.invoke is a synchronous function\n",
    "        output = chain.invoke(item.input, config={\"callbacks\": [handler]})\n",
    "\n",
    "        # Assuming handler.root_span.score is a synchronous function\n",
    "        handler.trace.score(\n",
    "            name=\"accuracy\",\n",
    "            value=simple_evaluation(output, item.expected_output)\n",
    "        )\n",
    "        print('.', end='', flush=True)\n",
    "\n",
    "    # for item in dataset.items:\n",
    "    #    process_item(item)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        executor.map(process_item, dataset.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c641ff7c-87d3-4c65-8ee6-e7c27aa35dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    }
   ],
   "source": [
    "run_evaluation(chain_v1, \"my-dataset\", \"v1-\"+datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "\n",
    "# ä¿è¯å…¨éƒ¨æ•°æ®åŒæ­¥åˆ°äº‘ç«¯\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e617b8-d637-4b7e-977c-0802359c19e4",
   "metadata": {},
   "source": [
    "### 1.4.5ã€Prompt è°ƒä¼˜ä¸å›å½’æµ‹è¯•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08909eaa-566f-49c6-bde1-ddbbbb223438",
   "metadata": {},
   "source": [
    "ä¼˜åŒ– Promptï¼šè¯•è¯•æ€ç»´é“¾ï¼ˆå›å¿†[ç¬¬äºŒè¯¾](../02-prompt/index.ipynb)ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "910b8550-8dde-44f4-8983-5ea398449f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "need_answer = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "ä½ æ˜¯AIGCè¯¾ç¨‹çš„åŠ©æ•™ï¼Œä½ çš„å·¥ä½œæ˜¯ä»å­¦å‘˜çš„è¯¾å ‚äº¤æµä¸­é€‰æ‹©å‡ºéœ€è¦è€å¸ˆå›ç­”çš„é—®é¢˜ï¼ŒåŠ ä»¥æ•´ç†ä»¥äº¤ç»™è€å¸ˆå›ç­”ã€‚\n",
    "\n",
    "ä½ çš„é€‰æ‹©éœ€è¦éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š\n",
    "1 éœ€è¦è€å¸ˆå›ç­”çš„é—®é¢˜æ˜¯æŒ‡ä¸è¯¾ç¨‹å†…å®¹æˆ–AI/LLMç›¸å…³çš„æŠ€æœ¯é—®é¢˜ï¼›\n",
    "2 è¯„è®ºæ€§çš„è§‚ç‚¹ã€é—²èŠã€è¡¨è¾¾æ¨¡ç³Šä¸æ¸…çš„å¥å­ï¼Œä¸éœ€è¦è€å¸ˆå›ç­”ï¼›\n",
    "3 å­¦ç”Ÿè¾“å…¥ä¸æ„æˆç–‘é—®å¥çš„ï¼Œä¸éœ€è¦è€å¸ˆå›ç­”ï¼›\n",
    "4 å­¦ç”Ÿé—®é¢˜ä¸­å¦‚æœç”¨â€œè¿™â€ã€â€œé‚£â€ç­‰ä»£è¯æŒ‡ä»£ï¼Œä¸ç®—è¡¨è¾¾æ¨¡ç³Šä¸æ¸…ï¼Œè¯·æ ¹æ®é—®é¢˜å†…å®¹åˆ¤æ–­æ˜¯å¦éœ€è¦è€å¸ˆå›ç­”ã€‚\n",
    " \n",
    "è¯¾ç¨‹å†…å®¹:\n",
    "{outlines}\n",
    "*********\n",
    "å­¦å‘˜è¾“å…¥:\n",
    "{user_input}\n",
    "*********\n",
    "Analyse the student's input according to the lecture's contents and your criteria.\n",
    "Output your analysis process step by step.\n",
    "Finally, output a single letter Y or N in a separate line.\n",
    "Y means that the input needs to be answered by the teacher.\n",
    "N means that the input does not needs to be answered by the teacher.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70d0f431-c8a3-4385-9738-ecf24a0b6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "import re\n",
    "\n",
    "\n",
    "class MyOutputParser(BaseOutputParser):\n",
    "    \"\"\"è‡ªå®šä¹‰parserï¼Œä»æ€ç»´é“¾ä¸­å–å‡ºæœ€åçš„Y/N\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        matches = re.findall(r'[YN]', text)\n",
    "        return matches[-1] if matches else 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59b2375a-2b7d-4398-8a63-0c4c289da34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_v2 = (\n",
    "    need_answer\n",
    "    | model\n",
    "    | MyOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ae178-c194-42c5-b21f-0d165b5506f0",
   "metadata": {},
   "source": [
    "å›å½’æµ‹è¯•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76456796-2fa2-4cd9-ae71-d6fbcb65d472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    }
   ],
   "source": [
    "run_evaluation(chain_v2, \"my-dataset\", \"cot-\"+datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "\n",
    "# ä¿è¯å…¨éƒ¨æ•°æ®åŒæ­¥åˆ°äº‘ç«¯\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5d874-95bb-4a81-8924-f97f00a6a6dc",
   "metadata": {},
   "source": [
    "### 1.5ã€Prompt ç‰ˆæœ¬ç®¡ç†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd11a845-f9e2-4110-9223-53ffc428b280",
   "metadata": {},
   "source": [
    "<img src=\"prompt_management.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278643de-1354-4526-9f25-553d62deee23",
   "metadata": {},
   "source": [
    "ç›®å‰åªæ”¯æŒ Langfuse è‡ªå·±çš„ SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fece2096-b931-45cb-9754-28b3969b8cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "ä½ æ˜¯AIGCè¯¾ç¨‹çš„åŠ©æ•™ï¼Œä½ çš„å·¥ä½œæ˜¯ä»å­¦å‘˜çš„è¯¾å ‚äº¤æµä¸­é€‰æ‹©å‡ºéœ€è¦è€å¸ˆå›ç­”çš„é—®é¢˜ï¼ŒåŠ ä»¥æ•´ç†ä»¥äº¤ç»™è€å¸ˆå›ç­”ã€‚\n",
      " \n",
      "è¯¾ç¨‹å†…å®¹:\n",
      "test\n",
      "*********\n",
      "å­¦å‘˜è¾“å…¥:\n",
      "è€å¸ˆå¥½\n",
      "*********\n",
      "å¦‚æœè¿™æ˜¯ä¸€ä¸ªéœ€è¦è€å¸ˆç­”ç–‘çš„é—®é¢˜ï¼Œå›å¤Yï¼Œå¦åˆ™å›å¤Nã€‚\n",
      "åªå›å¤Yæˆ–Nï¼Œä¸è¦å›å¤å…¶ä»–å†…å®¹ã€‚\n"
     ]
    }
   ],
   "source": [
    "# æŒ‰åç§°åŠ è½½\n",
    "prompt = langfuse.get_prompt(\"need_answer_v1\")\n",
    "\n",
    "# æŒ‰åç§°å’Œç‰ˆæœ¬å·åŠ è½½\n",
    "prompt = langfuse.get_prompt(\"need_answer_v1\", version=2)\n",
    "\n",
    "# å¯¹æ¨¡æ¿ä¸­çš„å˜é‡èµ‹å€¼\n",
    "compiled_prompt = prompt.compile(input=\"è€å¸ˆå¥½\", outlines=\"test\")\n",
    "\n",
    "print(compiled_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c19bb1b6-e346-4967-bfb8-22993e00a187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temperature': 0}\n"
     ]
    }
   ],
   "source": [
    "# è·å– config\n",
    "\n",
    "prompt = langfuse.get_prompt(\"need_answer_v1\", version=5)\n",
    "\n",
    "print(prompt.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc85360b-ab9a-4fac-919b-c84b691e760c",
   "metadata": {},
   "source": [
    "### 1.6ã€å¦‚ä½•æ¯”è¾ƒä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼æ€§ï¼šä¸€äº›ç»å…¸ NLP çš„è¯„æµ‹æ–¹æ³•ï¼ˆé€‰ï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ea3a5-e750-4a21-a092-a7d1cadf1a21",
   "metadata": {},
   "source": [
    "1. **ç¼–è¾‘è·ç¦»**ï¼šä¹Ÿå«è±æ–‡æ–¯å¦è·ç¦»(Levenshtein),æ˜¯é’ˆå¯¹äºŒä¸ªå­—ç¬¦ä¸²çš„å·®å¼‚ç¨‹åº¦çš„é‡åŒ–é‡æµ‹ï¼Œé‡æµ‹æ–¹å¼æ˜¯çœ‹è‡³å°‘éœ€è¦å¤šå°‘æ¬¡çš„å¤„ç†æ‰èƒ½å°†ä¸€ä¸ªå­—ç¬¦ä¸²å˜æˆå¦ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚\n",
    "   - å…·ä½“è®¡ç®—è¿‡ç¨‹æ˜¯ä¸€ä¸ªåŠ¨æ€è§„åˆ’ç®—æ³•ï¼šhttps://zhuanlan.zhihu.com/p/164599274\n",
    "   - è¡¡é‡ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼åº¦æ—¶ï¼Œå¯ä»¥ä»¥è¯ä¸ºå•ä½è®¡ç®—\n",
    "2. **BLEU Score**:\n",
    "   - è®¡ç®—è¾“å‡ºä¸å‚ç…§å¥ä¹‹é—´çš„ n-gram å‡†ç¡®ç‡ï¼ˆn=1...4ï¼‰\n",
    "   - å¯¹çŸ­è¾“å‡ºåšæƒ©ç½š\n",
    "   - åœ¨æ•´ä¸ªæµ‹è¯•é›†ä¸Šå¹³å‡ä¸‹è¿°å€¼\n",
    "   - å®Œæ•´è®¡ç®—å…¬å¼ï¼š$\\mathrm{BLEU}_4=\\min\\left(1,\\frac{output-length}{reference-length}\\right)\\left(\\prod_{i=1}^4 precision_i\\right)^{\\frac{1}{4}}$\n",
    "   - å‡½æ•°åº“ï¼šhttps://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "3. **Rouge Score**:\n",
    "   - Rouge-Nï¼šå°†æ¨¡å‹ç”Ÿæˆçš„ç»“æœå’Œæ ‡å‡†ç»“æœæŒ‰ N-gram æ‹†åˆ†åï¼Œåªè®¡ç®—å¬å›ç‡ï¼›\n",
    "   - Rouge-L: åˆ©ç”¨äº†æœ€é•¿å…¬å…±å­åºåˆ—ï¼ˆLongest Common Sequenceï¼‰ï¼Œè®¡ç®—ï¼š$P=\\frac{LCS(c,r)}{len(c)}$, $R=\\frac{LCS(c,r)}{len(r)}$, $F=\\frac{(1+\\beta^2)PR}{R+\\beta^2P}$\n",
    "   - å‡½æ•°åº“ï¼šhttps://pypi.org/project/rouge-score/\n",
    "   - å¯¹æ¯” BLEU ä¸ ROUGEï¼š\n",
    "     - BLEU èƒ½è¯„ä¼°æµç•…åº¦ï¼Œä½†æŒ‡æ ‡åå‘äºè¾ƒçŸ­çš„ç¿»è¯‘ç»“æœï¼ˆbrevity penalty æ²¡æœ‰æƒ³è±¡ä¸­é‚£ä¹ˆå¼ºï¼‰\n",
    "     - ROUGE ä¸ç®¡æµç•…åº¦ï¼Œæ‰€ä»¥åªé€‚åˆæ·±åº¦å­¦ä¹ çš„ç”Ÿæˆæ¨¡å‹ï¼šç»“æœéƒ½æ˜¯æµç•…çš„å‰æä¸‹ï¼ŒROUGE ååº”å‚ç…§å¥ä¸­å¤šå°‘å†…å®¹è¢«ç”Ÿæˆçš„å¥å­åŒ…å«ï¼ˆå¬å›ï¼‰\n",
    "4. **METEOR**: å¦ä¸€ä¸ªä»æœºå™¨ç¿»è¯‘é¢†åŸŸå€Ÿé‰´çš„æŒ‡æ ‡ã€‚ä¸ BLEU ç›¸æ¯”ï¼ŒMETEOR è€ƒè™‘äº†æ›´å¤šçš„å› ç´ ï¼Œå¦‚åŒä¹‰è¯åŒ¹é…ã€è¯å¹²åŒ¹é…ã€è¯åºç­‰ï¼Œå› æ­¤å®ƒé€šå¸¸è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªæ›´å…¨é¢çš„è¯„ä»·æŒ‡æ ‡ã€‚\n",
    "   - å¯¹è¯­è¨€å­¦å’Œè¯­ä¹‰è¯è¡¨æœ‰ä¾èµ–ï¼Œæ‰€ä»¥å¯¹è¯­è¨€ä¾èµ–å¼ºã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653506c-68d6-44ac-ad08-861ec4b54650",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>åˆ’é‡ç‚¹ï¼š</b>æ­¤ç±»æ–¹æ³•å¸¸ç”¨äºå¯¹æ–‡æœ¬ç”Ÿæˆæ¨¡å‹çš„è‡ªåŠ¨åŒ–è¯„ä¼°ã€‚å®é™…ä½¿ç”¨ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸æ›´å…³æ³¨ç›¸å¯¹å˜åŒ–è€Œä¸æ˜¯ç»å¯¹å€¼ï¼ˆè°ƒä¼˜è¿‡ç¨‹ä¸­æŒ‡æ ‡æ˜¯ä¸æ˜¯åœ¨å˜å¥½ï¼‰ã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677669d-a7cb-469d-860c-02338c8fe225",
   "metadata": {},
   "source": [
    "### 1.7ã€åŸºäº LLM çš„æµ‹è¯•æ–¹æ³•\n",
    "\n",
    "LangFuse é›†æˆäº†ä¸€äº›åŸç”Ÿçš„åŸºäº LLM çš„è‡ªåŠ¨æµ‹è¯•æ ‡å‡†ã€‚\n",
    "\n",
    "å…·ä½“å‚è€ƒï¼šhttps://langfuse.com/docs/scores/model-based-evals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c522be03-c20b-48ad-b5fb-c1436ce9ae74",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>åˆ’é‡ç‚¹ï¼š</b>æ­¤ç±»æ–¹æ³•ï¼Œå¯¹äºç”¨äºè¯„ä¼°çš„ LLM è‡ªèº«èƒ½åŠ›æœ‰è¦æ±‚ã€‚éœ€æ ¹æ®å…·ä½“æƒ…å†µé€‰æ‹©ä½¿ç”¨ã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23182a1b-bd91-4879-8c87-c199d2d5be70",
   "metadata": {},
   "source": [
    "### 1.8ã€ä¸ LlamaIndex é›†æˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff3ed1-3273-4c97-b870-d703cbd3e4b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d1a617-0844-41c8-bac4-9bd852300c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from langfuse.llama_index import LlamaIndexCallbackHandler\n",
    "\n",
    "# å®šä¹‰ LangFuse çš„ CallbackHandler\n",
    "langfuse_callback_handler = LlamaIndexCallbackHandler()\n",
    "\n",
    "# ä¿®æ”¹ LlamaIndex çš„å…¨å±€è®¾å®š\n",
    "Settings.callback_manager = CallbackManager([langfuse_callback_handler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cc42f34-b03e-4330-bc95-ec20b10e7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# æŒ‡å®šå…¨å±€llmä¸embeddingæ¨¡å‹\n",
    "Settings.llm = OpenAI(temperature=0, model=\"gpt-4o\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\", dimensions=512)\n",
    "Settings.transforms = [SentenceSplitter(chunk_size=300, chunk_overlap=100)]\n",
    "\n",
    "# åŠ è½½ pdf æ–‡æ¡£\n",
    "documents = SimpleDirectoryReader(\"./data\", file_extractor={\".pdf\": PyMuPDFReader()}).load_data()\n",
    "\n",
    "# æŒ‡å®š Vector Store ç”¨äº index\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# æ„å»ºå•è½® query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3761c13d-1701-4c7b-801e-a6ccfbe46696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2æœ‰7Bã€13Bå’Œ70Bå‚æ•°çš„å˜ä½“ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"llama2æœ‰å¤šå°‘å‚æ•°\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e4b5f-c28d-491f-8d7f-128e4068b702",
   "metadata": {},
   "source": [
    "è‡ªå®šä¹‰ Trace å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30314181-e74f-4ef8-b54c-711ffe7db8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse_callback_handler.set_trace_params(\n",
    "    user_id=\"wzr\",\n",
    "    session_id=\"llamaindex-session\",\n",
    "    tags=[\"demo\"]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2063efe2-b862-4310-937b-10ecd5fcf191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 å’Œ Llama 2-Chat æ˜¯æ–°æŠ€æœ¯ï¼Œä½¿ç”¨æ—¶å¯èƒ½å­˜åœ¨æ½œåœ¨é£é™©ã€‚å°½ç®¡è¿›è¡Œäº†å®‰å…¨æ€§è¯„ä¼°ï¼Œä½†ç”±äºæç¤ºé›†çš„å±€é™æ€§ã€å®¡æŸ¥æŒ‡å—çš„ä¸»è§‚æ€§ä»¥åŠè¯„ä¼°è€…çš„ä¸»è§‚æ€§ï¼Œè¿™äº›è¯„ä¼°ç»“æœå¯èƒ½å­˜åœ¨åè§ã€‚åœ¨éƒ¨ç½² Llama 2-Chat çš„åº”ç”¨ç¨‹åºä¹‹å‰ï¼Œå¼€å‘äººå‘˜åº”è¿›è¡Œé’ˆå¯¹å…¶ç‰¹å®šåº”ç”¨çš„å®‰å…¨æµ‹è¯•å’Œè°ƒæ•´ã€‚\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"llama2å®‰å…¨å—\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50977d19-717a-4a42-b792-f117e8d75c08",
   "metadata": {},
   "source": [
    "æ›´å¤šæ¥å£ä¸å‚æ•°ï¼Œè¯·å‚è€ƒ[å®˜æ–¹æ–‡æ¡£](https://langfuse.com/docs/integrations/llama-index/get-started)ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f2552-f3af-4484-91e3-3c2308c05921",
   "metadata": {},
   "source": [
    "## 2ã€LangSmith\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b102754-5cbc-457f-82c7-7264795bd2ea",
   "metadata": {},
   "source": [
    "LangChain å®˜æ–¹çš„ SaaS æœåŠ¡ï¼Œä¸å¼€æºã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f950af-34cd-43f1-a1a2-ed18d3743f1f",
   "metadata": {},
   "source": [
    "å¹³å°å…¥å£ï¼šhttps://www.langchain.com/langsmith\n",
    "\n",
    "æ–‡æ¡£åœ°å€ï¼šhttps://python.langchain.com/docs/langsmith/walkthrough\n",
    "\n",
    "å°†ä½ çš„ LangChain åº”ç”¨ä¸ LangSmith é“¾æ¥ï¼Œéœ€è¦ï¼š\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc59a7c-53c9-438b-a439-752eb68e817b",
   "metadata": {},
   "source": [
    "1. å®‰è£… LangSmith\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a797c266-3cac-468b-8ce8-3892d32df9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc6ce9-e39a-4c3f-8182-95c7c333729c",
   "metadata": {},
   "source": [
    "2. æ³¨å†Œè´¦å·ï¼Œå¹¶ç”³è¯·ä¸€ä¸ª`LANGCHAIN_API_KEY`\n",
    "3. åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®ä»¥ä¸‹å€¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77875bb-76ca-4737-afa9-5796064e6e10",
   "metadata": {},
   "source": [
    "```shell\n",
    "export LANGCHAIN_TRACING_V2=true\n",
    "export LANGCHAIN_PROJECT=YOUR_PROJECT_NAME #è‡ªå®šä¹‰é¡¹ç›®åç§°ï¼ˆå¯é€‰ï¼‰\n",
    "export LANGCHAIN_API_KEY=LANGCHAIN_API_KEY # LangChain API Key\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de823435-67b7-4f96-974a-4588fad8a1ef",
   "metadata": {},
   "source": [
    "3. ç¨‹åºä¸­çš„è°ƒç”¨å°†è‡ªåŠ¨è¢«è®°å½•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df088b92-f10c-4d79-9b3c-43281d26edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__44058e8374214bef8cf7eb0842718fe9\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"hello-world-\"+datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31a3eb-9fbf-408c-b2fc-5b5f3cb16268",
   "metadata": {},
   "source": [
    "### 2.1ã€åŸºæœ¬åŠŸèƒ½æ¼”ç¤º\n",
    "\n",
    "1. Traces\n",
    "2. LLM Calls\n",
    "3. Monitor\n",
    "4. Playground\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59edfa6-2282-48ee-9c97-7af6a2532ddf",
   "metadata": {},
   "source": [
    "<img src=\"langsmith-example.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c40ab291-d315-44fd-a8db-2aa17cb7443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"Say hello to {input}!\")\n",
    "])\n",
    "\n",
    "\n",
    "# å®šä¹‰è¾“å‡ºè§£æå™¨\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32cd5e04-e92c-411e-ab7d-84529600aca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello ç‹å“ç„¶! Nice to meet you!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"ç‹å“ç„¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c59c7c0-9e49-4230-841c-900487b716cb",
   "metadata": {},
   "source": [
    "### 2.2ã€æ•°æ®é›†ç®¡ç†ä¸æµ‹è¯•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e0dd2-7ea4-4799-9fc6-4b786a8302d3",
   "metadata": {},
   "source": [
    "### 2.2.1ã€åœ¨çº¿æ ‡æ³¨æ¼”ç¤º\n",
    "\n",
    "<img src=\"langsmith-annotation.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b4a82-8f91-480e-8e7c-0f7941314c7c",
   "metadata": {},
   "source": [
    "### 2.2.2ã€ä¸Šä¼ æ•°æ®é›†\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f6863f5-e368-4ec7-a51c-97ea6c6032b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('my_annotations.jsonl', 'r', encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        example = json.loads(line.strip())\n",
    "        item = {\n",
    "            \"input\": {\n",
    "                \"outlines\": example[\"outlines\"],\n",
    "                \"user_input\": example[\"user_input\"]\n",
    "            },\n",
    "            \"expected_output\": example[\"label\"]\n",
    "        }\n",
    "        data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e978a2d-74cd-4b9c-a3cb-18f81b091c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"assistant-\"+datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name,  # æ•°æ®é›†åç§°\n",
    "    description=\"AGIClassçº¿ä¸Šè·Ÿè¯¾åŠ©æ‰‹çš„æ ‡æ³¨æ•°æ®\",  # æ•°æ®é›†æè¿°\n",
    ")\n",
    "\n",
    "inputs, outputs = zip(\n",
    "    *[({\"input\": item[\"input\"]}, {\"label\": item[\"expected_output\"]}) for item in data[:50]]\n",
    ")\n",
    "client.create_examples(inputs=inputs, outputs=outputs, dataset_id=dataset.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f473e5-3873-42d0-b900-f0d9cea94412",
   "metadata": {},
   "source": [
    "### 2.2.3ã€è¯„ä¼°å‡½æ•°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3813b43c-7ecd-46e3-9a2c-9b880bfea413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "def correct_label(root_run: Run, example: Example) -> dict:\n",
    "    score = root_run.outputs.get(\"output\") == example.outputs.get(\"label\")\n",
    "    return {\"score\": int(score), \"key\": \"accuracy\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef2db5-39d8-4e0a-aa1c-4235944acd93",
   "metadata": {},
   "source": [
    "### 2.2.4ã€è¿è¡Œæµ‹è¯•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c56d52ec-d58a-4720-a9a4-1b8f8130d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "\n",
    "need_answer = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "ä½ æ˜¯AIGCè¯¾ç¨‹çš„åŠ©æ•™ï¼Œä½ çš„å·¥ä½œæ˜¯ä»å­¦å‘˜çš„è¯¾å ‚äº¤æµä¸­é€‰æ‹©å‡ºéœ€è¦è€å¸ˆå›ç­”çš„é—®é¢˜ï¼ŒåŠ ä»¥æ•´ç†ä»¥äº¤ç»™è€å¸ˆå›ç­”ã€‚\n",
    " \n",
    "è¯¾ç¨‹å†…å®¹:\n",
    "{outlines}\n",
    "*********\n",
    "å­¦å‘˜è¾“å…¥:\n",
    "{user_input}\n",
    "*********\n",
    "å¦‚æœè¿™æ˜¯ä¸€ä¸ªéœ€è¦è€å¸ˆç­”ç–‘çš„é—®é¢˜ï¼Œå›å¤Yï¼Œå¦åˆ™å›å¤Nã€‚\n",
    "åªå›å¤Yæˆ–Nï¼Œä¸è¦å›å¤å…¶ä»–å†…å®¹ã€‚\"\"\")\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_kwargs={\"seed\": 42})\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain_v1 = need_answer | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1aeb92ae-8b3a-482f-b8cf-a6a08c11b492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'Acc-5957b0ea' at:\n",
      "https://smith.langchain.com/o/97b8262a-9ab9-4b43-afeb-21ea05a90ba7/datasets/c48c4fd2-cd43-4928-9cb5-75ba8abdb111/compare?selectedSessions=f011b26e-017d-4339-b37c-a5c6eeaaffc9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:13,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "results = evaluate(\n",
    "    lambda inputs: chain_v1.invoke(inputs[\"input\"]),\n",
    "    data=dataset_name,\n",
    "    evaluators=[correct_label],\n",
    "    experiment_prefix=\"Acc\",\n",
    "    description=\"æµ‹è¯•ChainV1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1d803-5b09-4756-89a1-8377c22300e5",
   "metadata": {},
   "source": [
    "### 2.2.5ã€åŸºäº LLM çš„è¯„ä¼°å‡½æ•°\n",
    "\n",
    "https://docs.smith.langchain.com/evaluation/faq/evaluator-implementations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e365c65-9d5a-4fba-8d9d-b1be247f90c2",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881722dc-400a-451a-abbf-4324a0a5c2db",
   "metadata": {},
   "source": [
    "ç®¡ç†ä¸€ä¸ª LLM åº”ç”¨çš„å…¨ç”Ÿå‘½å‘¨æœŸï¼Œéœ€è¦ç”¨åˆ°ä»¥ä¸‹å·¥å…·ï¼š\n",
    "\n",
    "1. è°ƒè¯• Prompt çš„ Playground\n",
    "2. æµ‹è¯•/éªŒè¯ç³»ç»Ÿçš„ç›¸å…³æŒ‡æ ‡\n",
    "3. æ•°æ®é›†ç®¡ç†\n",
    "4. å„ç§æŒ‡æ ‡ç›‘æ§ä¸ç»Ÿè®¡ï¼šè®¿é—®é‡ã€å“åº”æ—¶é•¿ã€Token è´¹ç­‰ç­‰\n",
    "\n",
    "æ ¹æ®è‡ªå·±çš„æŠ€æœ¯æ ˆï¼Œé€‰æ‹©ï¼š\n",
    "\n",
    "1. LangFuseï¼šå¼€æºå¹³å°ï¼Œæ”¯æŒ LangChain å’ŒåŸç”Ÿ OpenAI API\n",
    "2. LangSmith: LangChain çš„åŸå§‹ç®¡ç†å¹³å°\n",
    "3. Prompt Flowï¼šå¼€æºå¹³å°ï¼Œæ”¯æŒ Semantic Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd761c5-485c-4f1c-993c-990e13a1aca6",
   "metadata": {},
   "source": [
    "## ä½œä¸š\n",
    "\n",
    "é€‰æ‹©ä¸€ä¸ªå·¥å…·å¹³å°ï¼Œå¯¹è‡ªå·±ä¹‹å‰å¼€å‘çš„ç³»ç»Ÿæˆ–æ¨¡å‹åšæ‰¹é‡æµ‹è¯•\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
